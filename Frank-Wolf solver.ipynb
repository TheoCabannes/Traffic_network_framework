{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'data/braess'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We load the graph and the demand\n",
    "Both graph and demand are in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   3. 100.]]\n"
     ]
    }
   ],
   "source": [
    "# in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix\n",
    "try:\n",
    "    demand.shape[1]\n",
    "except:\n",
    "    demand = np.array([demand])\n",
    "nb_ods = int(demand.shape[0])\n",
    "demand[0][0] = 10\n",
    "print(demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then store the links in a dictionary\n",
    "\n",
    "$\\underline{\\text{Edit:}}$ we don't need it anymore, we store the graph adjacency matrix as a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "graph_dict = {}\n",
    "for i in range(graph.shape[0]):\n",
    "    try: \n",
    "        graph_dict[int(graph[i][1])]\n",
    "    except:\n",
    "        graph_dict[int(graph[i][1])] = {}\n",
    "    graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    \n",
    "# print(graph_dict)\n",
    "# Here we remove graph_dict\n",
    "#del graph_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the function which gives the travel time as a function of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO ADD THE CAPACITY\n",
    "def travel_time(f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [float('inf') for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i] else float('inf') for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "nb_links = int(np.max(graph[:,0])+1)\n",
    "nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "print(nb_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We compute the all or nothing flow allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import dijkstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Dijkstra's algorithm class of scipy we need to define the adjacent matrix of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_travel_time(tt):\n",
    "    for i in range(graph.shape[0]):\n",
    "        # G[int(graph[i][1])].getcol(int(graph[i][2])).toarray().reshape(1)[0]\n",
    "        # G[int(graph[i][1])][int(graph[i][2])] = tt[i]\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t2.0\n",
      "  (1, 2)\t0.25\n",
      "  (1, 3)\t2.0\n",
      "  (2, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "update_travel_time(travel_time(np.zeros(nb_links))) # , [1,1,-1,1,1]))\n",
    "# the following line make the matrix sparse, one can use G.toarray() to do the opposite\n",
    "G = scipy.sparse.csr_matrix(G)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class path:\n",
    "    def __init__(self,links):\n",
    "        self.links = links\n",
    "        self.flow = 0\n",
    "    def add_flow(self, flow):\n",
    "        self.flow += flow\n",
    "    def __eq__(self, other):\n",
    "        return np.all(self.links == other.links)\n",
    "    def __hash__(self):\n",
    "        return hash(np.sum([hash(self.links[i]*(nb_links**i)) for i in range(len(self.links))]))\n",
    "    def __str__(self):\n",
    "        return str(self.flow) + \" is on \" + str(self.links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{430: (<__main__.path object at 0x113f9eac8>, 0)}\n",
      "{430: (<__main__.path object at 0x113f9eac8>, 0), 405: (<__main__.path object at 0x113f9e6d8>, 0)}\n",
      "{430: (<__main__.path object at 0x113f9eac8>, 0), 405: (<__main__.path object at 0x113f9e6d8>, 0), 425: (<__main__.path object at 0x113f9e630>, 0)}\n"
     ]
    }
   ],
   "source": [
    "paths_used = {}\n",
    "print(paths_used)\n",
    "p = path([0, 1, 2, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)\n",
    "p = path([0, 1, 1, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)\n",
    "p = path([0, 0, 2, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the all or nothing allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the all or nothing flow\n",
    "paths_used = {}\n",
    "i = 0\n",
    "\n",
    "def all_or_nothing():\n",
    "    faon = np.zeros(nb_links)\n",
    "    # using scipy to compute dijkstra\n",
    "    dist_matrix, return_predecessors = dijkstra(G, return_predecessors = True)\n",
    "    \"\"\"faon = np.zeros(shape = nb_links)\"\"\"\n",
    "    for i in range(nb_ods):\n",
    "        o_tmp = int(demand[i][0])\n",
    "        d_tmp = int(demand[i][1])\n",
    "        flow_tmp = demand[i][2]\n",
    "\n",
    "        node_tmp = d_tmp\n",
    "        links = []\n",
    "        while node_tmp != o_tmp:\n",
    "            node_tmp_d = return_predecessors[o_tmp][node_tmp]\n",
    "            link_tmp = list(G.todok().keys()).index((node_tmp_d, node_tmp)) #I don't know how much time it takes, should I stock the list of keys in memory?\n",
    "            links.insert(0, link_tmp)\n",
    "            faon[link_tmp] += flow_tmp\n",
    "            node_tmp = node_tmp_d\n",
    "        \n",
    "        p = path(links)\n",
    "        p.add_flow(flow_tmp)\n",
    "        print(p)\n",
    "        if hash(p) in paths_used:\n",
    "            continue\n",
    "            # print(str(p) + \" is already in paths_used\" + str(paths_used[hash(p)]))\n",
    "        else:\n",
    "            paths_used[hash(p)] = (p, i)\n",
    "            i = i+1\n",
    "    \n",
    "        # Here store the path\n",
    "        # p = np.zeros()\n",
    "        # next is for the link flow\n",
    "        \"\"\"\n",
    "        node_tmp_d = d_tmp\n",
    "        while node_tmp_d != o_tmp:\n",
    "            node_tmp = return_predecessors[o_tmp][node_tmp_d]\n",
    "            link_tmp = int(graph_dict[node_tmp][node_tmp_d])\n",
    "            faon[link_tmp] += flow_tmp\n",
    "            node_tmp_d = node_tmp\n",
    "    return faon\n",
    "    \"\"\"\n",
    "    return faon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 is on [1, 4]\n",
      "{21: (<__main__.path object at 0x113dd72b0>, 0)}\n"
     ]
    }
   ],
   "source": [
    "all_or_nothing()\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: rewrite this function\n",
    "def potential(graph, f):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    links = int(np.max(graph[:, 0]) + 1)\n",
    "    g = np.copy(\n",
    "        graph.dot(np.diag([1., 1., 1., 1., 1 / 2., 1 / 3., 1 / 4., 1 / 5.])))\n",
    "    x = np.power(f.reshape((links, 1)), np.array([1, 2, 3, 4, 5]))\n",
    "    return np.sum(np.einsum('ij,ij->i', x, g[:, 3:]))\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let run the Frank-Wolf's algorithm with a line search to find alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 is on [1, 4]\n",
      "[  0. 100.   0.   0. 100.]\n",
      "0\n",
      "100.0 is on [0, 3]\n",
      "0\n",
      "0.5\n",
      "100.0 is on [1, 4]\n"
     ]
    }
   ],
   "source": [
    "eps=1e-8\n",
    "f = all_or_nothing()\n",
    "print(f)\n",
    "update_travel_time(travel_time(f))\n",
    "\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    faon = all_or_nothing() \n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon))\n",
    "    if(i%100==0):\n",
    "        print(i)\n",
    "        print(s)\n",
    "    if s < eps:\n",
    "        break\n",
    "    f = (1. - s) * f + s * faon\n",
    "    update_travel_time(travel_time(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t6.0\n",
      "  (0, 2)\t2.0\n",
      "  (1, 2)\t0.25\n",
      "  (1, 3)\t2.0\n",
      "  (2, 3)\t6.0\n",
      "[50. 50.  0. 50. 50.]\n"
     ]
    }
   ],
   "source": [
    "print(G)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_travel_time(travel_time(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
