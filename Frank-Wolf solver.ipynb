{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following problem (TAP-C):\n",
    "\\begin{align}\n",
    "\\min_{f, h} &\\sum_{a} \\int_{0}^{f_a} c_a(s)\\; \\text{d}s\n",
    "\\\\\n",
    "\\text{s.t.  } & \\;\\; f = \\Delta h\n",
    "\\\\\n",
    "& \\;\\; \n",
    "h \\geq 0\n",
    "\\\\\n",
    "& \\;\\; \n",
    "A h = d\n",
    "\\\\\n",
    "& \\;\\; \n",
    "f \\leq u\n",
    "\\end{align}\n",
    "\n",
    "This problem is hard to compute, even if it is a convex problem. Computing all the path of a network is NP-hard (with respect to the number of edges and links).\n",
    "\n",
    "Nevertheless, the TAP can be solve using a Frank-Wolf algorithm:\n",
    "\\begin{align}\n",
    "&\\text{1. TO DO }\n",
    "\\\\\n",
    "&\\text{2. }\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "First, we tried to solve the STA with CVX.\n",
    "This does not work because the values of the travel time are to big. \n",
    "\n",
    "Secondly, we solve the STA using links flow. \n",
    "This does not help us in our project because we need the path flow to compute the dual of the TAP-C.\n",
    "\n",
    "Thirdly, we solve the STA using paths flow. \n",
    "The issue here is that finding every path in a network in a NP-complete problem. \n",
    "But if we can compute every path (we only need to do it one time), then it is really fast to compute the shortest path. We do not need to do a Dikjstra's algorithm to compute the shortest path, only a big matrix multiplication and a array sorting are enough. This might be more difficult on a laptop. But it might be faster on a HPC.\n",
    "\n",
    "Finally, we solve the STA using links flow and we compute the paths during the all or nothing step of the Frank Wolf algorithm. TO BE DONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network = I210\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We load the graph and the demand\n",
    "Both graph and demand are in csv file, we load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We need to demand to be an array like:\n",
    "[\n",
    "[o1, d1, demand from o1 to d1],\n",
    "...,\n",
    "[on, dn, demand from on to dn]\n",
    "]\n",
    "\n",
    "We need the graph to be an array like:\n",
    "[\n",
    "[id link 1, node origin link 1, node destination link 1, a1, a2, a3, a4],\n",
    "...,\n",
    "[id link n, node origin link n, node destination link n, a1, a2, a3, a4]\n",
    "]\n",
    "where the node are indexed from 0 to nb_nodes-1,\n",
    "    the links are indexed from 0 to nb_links-1\n",
    "\n",
    "One can add some checks here to be sure that demand and graph respect this format!\n",
    "\"\"\"\n",
    "\n",
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix (2d array)\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    return graph, demand\n",
    "\n",
    "graph, demand = cleaning_input(graph, demand)\n",
    "nb_links = int(np.max(graph[:,0])+1)\n",
    "nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "nb_ods = int(demand.shape[0])\n",
    "if debug:\n",
    "    print(\"nb nodes = \" + str(nb_nodes))\n",
    "    print(\"nb links = \" + str(nb_links))\n",
    "    print(\"nb ods = \" + str(nb_ods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the function which gives the travel time as a function of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here Max float is fixed to not overlap the maximum float number when we compute the potential function\n",
    "max_float = 1e+10\n",
    "if debug:\n",
    "    print(max_float)\n",
    "\n",
    "# TO DO ADD THE CAPACITY\n",
    "def travel_time(f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i] else max_float for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We compute the all or nothing flow allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import dijkstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Dijkstra's algorithm class of scipy we need to define the adjacent matrix of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_travel_time(tt):\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.38\n",
      "  (0, 6)\t1.15\n",
      "  (1, 2)\t1.38\n",
      "  (1, 7)\t1.14\n",
      "  (2, 3)\t1.68\n",
      "  (2, 8)\t1.13\n",
      "  (3, 4)\t1.26\n",
      "  (3, 9)\t1.05\n",
      "  (4, 5)\t2.25\n",
      "  (4, 10)\t1.04\n",
      "  (5, 11)\t1.09\n",
      "  (6, 0)\t1.15\n",
      "  (6, 7)\t0.48\n",
      "  (6, 12)\t0.36\n",
      "  (7, 1)\t1.14\n",
      "  (7, 8)\t0.48\n",
      "  (7, 13)\t0.39\n",
      "  (8, 2)\t1.13\n",
      "  (8, 9)\t0.58\n",
      "  (8, 14)\t0.38\n",
      "  (9, 3)\t1.05\n",
      "  (9, 10)\t0.43\n",
      "  (9, 15)\t0.48\n",
      "  (10, 4)\t1.04\n",
      "  (10, 11)\t0.77\n",
      "  (10, 16)\t0.5\n",
      "  (11, 5)\t1.09\n",
      "  (11, 17)\t0.47\n",
      "  (11, 19)\t0.22\n",
      "  (12, 6)\t0.36\n",
      "  (12, 13)\t1.38\n",
      "  (13, 7)\t0.39\n",
      "  (13, 14)\t1.38\n",
      "  (14, 8)\t0.38\n",
      "  (14, 15)\t1.68\n",
      "  (15, 9)\t0.48\n",
      "  (15, 16)\t1.25\n",
      "  (16, 10)\t0.5\n",
      "  (16, 17)\t2.22\n",
      "  (17, 11)\t0.47\n",
      "  (18, 6)\t0.29\n"
     ]
    }
   ],
   "source": [
    "G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "update_travel_time(travel_time(np.zeros(nb_links))) # , [1,1,-1,1,1]))\n",
    "# the following line make the matrix sparse, one can use G.toarray() to do the opposite\n",
    "G = scipy.sparse.csr_matrix(G)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class path:\n",
    "    def __init__(self,links):\n",
    "        self.links = links\n",
    "        self.flow = 0\n",
    "    def add_flow(self, flow):\n",
    "        self.flow += flow\n",
    "    def __eq__(self, other):\n",
    "        return np.all(self.links == other.links)\n",
    "    def __hash__(self):\n",
    "        return hash(np.sum([hash(self.links[i]*(nb_links**i)) for i in range(len(self.links))]))\n",
    "    def __str__(self):\n",
    "        return str(self.flow) + \" is on \" + str(self.links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{210166: (<__main__.path object at 0x1102f08d0>, 0)}\n",
      "{210166: (<__main__.path object at 0x1102f08d0>, 0), 208485: (<__main__.path object at 0x1102f0780>, 0)}\n",
      "{210166: (<__main__.path object at 0x1102f08d0>, 0), 208485: (<__main__.path object at 0x1102f0780>, 0), 210125: (<__main__.path object at 0x1102f0a90>, 0)}\n"
     ]
    }
   ],
   "source": [
    "paths_used = {}\n",
    "print(paths_used)\n",
    "p = path([0, 1, 2, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)\n",
    "p = path([0, 1, 1, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)\n",
    "p = path([0, 0, 2, 3])\n",
    "paths_used[hash(p)] = (p, 0)\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the all or nothing allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the all or nothing flow\n",
    "paths_used = {}\n",
    "\n",
    "def all_or_nothing():\n",
    "    global k\n",
    "    paths_used_tmp = {}\n",
    "    faon = np.zeros(nb_links)\n",
    "    # using scipy to compute dijkstra\n",
    "    dist_matrix, return_predecessors = dijkstra(G, return_predecessors = True)\n",
    "    \"\"\"faon = np.zeros(shape = nb_links)\"\"\"\n",
    "    for i in range(nb_ods):\n",
    "        o_tmp = int(demand[i][0])\n",
    "        d_tmp = int(demand[i][1])\n",
    "        flow_tmp = demand[i][2]\n",
    "\n",
    "        node_tmp = d_tmp\n",
    "        links = []\n",
    "        while node_tmp != o_tmp:\n",
    "            node_tmp_d = return_predecessors[o_tmp][node_tmp]\n",
    "            # link_tmp = list(G.todok().keys()).index((node_tmp_d, node_tmp)) #I don't know how much time it takes, should I stock the list of keys in memory?\n",
    "            link_tmp = graph_dict[path[i]][path[i+1]]\n",
    "            links.insert(0, link_tmp)\n",
    "            faon[link_tmp] += flow_tmp\n",
    "            node_tmp = node_tmp_d\n",
    "        \n",
    "        p = path(links)\n",
    "        p.add_flow(flow_tmp)\n",
    "        print(p)\n",
    "        if hash(p) in paths_used:\n",
    "            continue\n",
    "            # print(str(p) + \" is already in paths_used\" + str(paths_used[hash(p)]))\n",
    "        else:\n",
    "            print(k)\n",
    "            paths_used_tmp[hash(p)] = (p, k)\n",
    "            k = k+1\n",
    "            \n",
    "    paths_used.update(paths_used_tmp)\n",
    "    return faon, paths_used_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-029ee62734e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_or_nothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_used\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-1a1fe99335d9>\u001b[0m in \u001b[0;36mall_or_nothing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnode_tmp_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_predecessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo_tmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_tmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# link_tmp = list(G.todok().keys()).index((node_tmp_d, node_tmp)) #I don't know how much time it takes, should I stock the list of keys in memory?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlink_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfaon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink_tmp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflow_tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "k = 0 \n",
    "all_or_nothing()\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: rewrite this function\n",
    "def potential(graph, f):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    links = int(np.max(graph[:, 0]) + 1)\n",
    "    g = np.copy(\n",
    "        graph.dot(np.diag([1., 1., 1., 1., 1 / 2., 1 / 3., 1 / 4., 1 / 5.])))\n",
    "    x = np.power(f.reshape((links, 1)), np.array([1, 2, 3, 4, 5]))\n",
    "    return np.sum(np.einsum('ij,ij->i', x, g[:, 3:]))\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let run the Frank-Wolf's algorithm with a line search to find alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-4e12da69b0d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupdate_travel_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtravel_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_or_nothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mupdate_travel_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtravel_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-1a1fe99335d9>\u001b[0m in \u001b[0;36mall_or_nothing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnode_tmp_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_predecessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo_tmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_tmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# link_tmp = list(G.todok().keys()).index((node_tmp_d, node_tmp)) #I don't know how much time it takes, should I stock the list of keys in memory?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlink_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfaon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink_tmp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflow_tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "eps=1e-8\n",
    "k = 0\n",
    "paths_used = {}\n",
    "f = np.zeros(nb_links)\n",
    "update_travel_time(travel_time(f))\n",
    "\n",
    "f, paths_aux = all_or_nothing()\n",
    "print(f)\n",
    "update_travel_time(travel_time(f))\n",
    "print(paths_used)\n",
    "path_matrix = np.zeros(len(paths_aux))\n",
    "\n",
    "for val in paths_aux.values():\n",
    "    print(val[1])\n",
    "    path_matrix[val[1]] = val[0].flow\n",
    "\n",
    "print(path_matrix)\n",
    "\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    faon, paths_tmp = all_or_nothing() \n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon))\n",
    "    print(\"s: \" + str(s))\n",
    "    if s < eps:\n",
    "        break\n",
    "    path_matrix = np.append(path_matrix, np.zeros(len(paths_used)-path_matrix.shape[0]))\n",
    "    path_matrix = (1-s) * path_matrix\n",
    "    for val in paths_tmp.values():\n",
    "        path_matrix[val[1]] += s * val[0].flow\n",
    "    f = (1. - s) * f + s * faon\n",
    "    \n",
    "    # also update the path flow\n",
    "    ## TO DO ##\n",
    "    update_travel_time(travel_time(f))\n",
    "print(path_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8e+01 1.9e+01 2.5e+04]]\n",
      "  (0, 1)\t1.38\n",
      "  (0, 6)\t1.15\n",
      "  (1, 2)\t1.38\n",
      "  (1, 7)\t1.14\n",
      "  (2, 3)\t1.68\n",
      "  (2, 8)\t1.13\n",
      "  (3, 4)\t1.26\n",
      "  (3, 9)\t1.05\n",
      "  (4, 5)\t2.25\n",
      "  (4, 10)\t1.04\n",
      "  (5, 11)\t1.09\n",
      "  (6, 0)\t1.15\n",
      "  (6, 7)\t0.48\n",
      "  (6, 12)\t0.36\n",
      "  (7, 1)\t1.14\n",
      "  (7, 8)\t0.48\n",
      "  (7, 13)\t0.39\n",
      "  (8, 2)\t1.13\n",
      "  (8, 9)\t0.58\n",
      "  (8, 14)\t0.38\n",
      "  (9, 3)\t1.05\n",
      "  (9, 10)\t0.43\n",
      "  (9, 15)\t0.48\n",
      "  (10, 4)\t1.04\n",
      "  (10, 11)\t0.77\n",
      "  (10, 16)\t0.5\n",
      "  (11, 5)\t1.09\n",
      "  (11, 17)\t0.47\n",
      "  (11, 19)\t0.22\n",
      "  (12, 6)\t0.36\n",
      "  (12, 13)\t1.38\n",
      "  (13, 7)\t0.39\n",
      "  (13, 14)\t1.38\n",
      "  (14, 8)\t0.38\n",
      "  (14, 15)\t1.68\n",
      "  (15, 9)\t0.48\n",
      "  (15, 16)\t1.25\n",
      "  (16, 10)\t0.5\n",
      "  (16, 17)\t2.22\n",
      "  (17, 11)\t0.47\n",
      "  (18, 6)\t0.29\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for p in paths_used.values():\n",
    "    index = p[1]\n",
    "    p[0].add_flow(path_matrix[index] - p[0].flow)\n",
    "    print(str(path_matrix[index]) + \" is on \" + str(p[0]))\n",
    "\n",
    "print(demand)\n",
    "print(G)\n",
    "print(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.todok().keys()).index((7, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "["
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_float' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-55511aa19be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtravel_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_float' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"[\", end=\"\")\n",
    "for i in range(len(travel_time(f))):\n",
    "    print(max_float, end=\", \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000e+00 0.0000e+00 1.0000e+00 1.3800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.3120e+00]\n",
      " [1.0000e+00 0.0000e+00 6.0000e+00 1.1500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7600e+00]\n",
      " [2.0000e+00 1.0000e+00 2.0000e+00 1.3800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.3120e+00]\n",
      " [3.0000e+00 1.0000e+00 7.0000e+00 1.1400e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7360e+00]\n",
      " [4.0000e+00 2.0000e+00 3.0000e+00 1.6800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 4.0320e+00]\n",
      " [5.0000e+00 2.0000e+00 8.0000e+00 1.1300e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7120e+00]\n",
      " [6.0000e+00 3.0000e+00 4.0000e+00 1.2600e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.0240e+00]\n",
      " [7.0000e+00 3.0000e+00 9.0000e+00 1.0500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.5200e+00]\n",
      " [8.0000e+00 4.0000e+00 5.0000e+00 2.2500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 5.4000e+00]\n",
      " [9.0000e+00 4.0000e+00 1.0000e+01 1.0400e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.4960e+00]\n",
      " [1.0000e+01 5.0000e+00 1.1000e+01 1.0900e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.6160e+00]\n",
      " [1.1000e+01 6.0000e+00 0.0000e+00 1.1500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7600e+00]\n",
      " [1.2000e+01 6.0000e+00 7.0000e+00 4.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.8432e-03]\n",
      " [1.3000e+01 6.0000e+00 1.2000e+01 3.6000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 8.6400e-01]\n",
      " [1.4000e+01 7.0000e+00 1.0000e+00 1.1400e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7360e+00]\n",
      " [1.5000e+01 7.0000e+00 8.0000e+00 4.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.8432e-03]\n",
      " [1.6000e+01 7.0000e+00 1.3000e+01 3.9000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 9.3600e-01]\n",
      " [1.7000e+01 8.0000e+00 2.0000e+00 1.1300e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.7120e+00]\n",
      " [1.8000e+01 8.0000e+00 9.0000e+00 5.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.2272e-03]\n",
      " [1.9000e+01 8.0000e+00 1.4000e+01 3.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 9.1200e-01]\n",
      " [2.0000e+01 9.0000e+00 3.0000e+00 1.0500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.5200e+00]\n",
      " [2.1000e+01 9.0000e+00 1.0000e+01 4.3000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.6512e-03]\n",
      " [2.2000e+01 9.0000e+00 1.5000e+01 4.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.1520e+00]\n",
      " [2.3000e+01 1.0000e+01 4.0000e+00 1.0400e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.4960e+00]\n",
      " [2.4000e+01 1.0000e+01 1.1000e+01 7.7000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.9568e-03]\n",
      " [2.5000e+01 1.0000e+01 1.6000e+01 5.0000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.2000e+00]\n",
      " [2.6000e+01 1.1000e+01 5.0000e+00 1.0900e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 2.6160e+00]\n",
      " [2.7000e+01 1.1000e+01 1.7000e+01 4.7000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.1280e+00]\n",
      " [2.8000e+01 1.2000e+01 6.0000e+00 3.6000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 8.6400e-01]\n",
      " [2.9000e+01 1.2000e+01 1.3000e+01 1.3800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.3120e+00]\n",
      " [3.0000e+01 1.3000e+01 7.0000e+00 3.9000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 9.3600e-01]\n",
      " [3.1000e+01 1.3000e+01 1.4000e+01 1.3800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.3120e+00]\n",
      " [3.2000e+01 1.4000e+01 8.0000e+00 3.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 9.1200e-01]\n",
      " [3.3000e+01 1.4000e+01 1.5000e+01 1.6800e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 4.0320e+00]\n",
      " [3.4000e+01 1.5000e+01 9.0000e+00 4.8000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.1520e+00]\n",
      " [3.5000e+01 1.5000e+01 1.6000e+01 1.2500e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 3.0000e+00]\n",
      " [3.6000e+01 1.6000e+01 1.0000e+01 5.0000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.2000e+00]\n",
      " [3.7000e+01 1.6000e+01 1.7000e+01 2.2200e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 5.3280e+00]\n",
      " [3.8000e+01 1.7000e+01 1.1000e+01 4.7000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.1280e+00]\n",
      " [3.9000e+01 1.1000e+01 1.9000e+01 2.2000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 8.4480e-04]\n",
      " [4.0000e+01 1.8000e+01 6.0000e+00 2.9000e-01 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 1.1136e-03]]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7976931348623157e+308\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "max_float = sys.float_info.max\n",
    "print(max_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "graph_dict = {}\n",
    "for i in range(graph.shape[0]):\n",
    "    try: \n",
    "        graph_dict[int(graph[i][1])]\n",
    "    except:\n",
    "        graph_dict[int(graph[i][1])] = {}\n",
    "    graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    \n",
    "# print(graph_dict)\n",
    "# Here we remove graph_dict\n",
    "del graph_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test to run the algorithm with path flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. We load and clean the network and the demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network = I210\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    return graph, demand\n",
    "\n",
    "graph, demand = cleaning_input(graph, demand)\n",
    "nb_links = int(np.max(graph[:,0])+1)\n",
    "nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "nb_ods = int(demand.shape[0])\n",
    "if debug:\n",
    "    print(\"nb nodes = \" + str(nb_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. We compute the incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "   \n",
    "# This class represents a directed graph  \n",
    "# using adjacency list representation \n",
    "class Graph: \n",
    "   \n",
    "    def __init__(self,vertices): \n",
    "        #No. of vertices \n",
    "        self.V= vertices  \n",
    "        # default dictionary to store graph \n",
    "        self.graph = defaultdict(list)  \n",
    "   \n",
    "    # function to add an edge to graph \n",
    "    def addEdge(self,u,v): \n",
    "        self.graph[u].append(v) \n",
    "   \n",
    "    def printAllPathsUtil(self, u, d, visited, path, graph_dict): \n",
    "        # Mark the current node as visited and store in path \n",
    "        visited[u]= True\n",
    "        path.append(u) \n",
    "        \n",
    "        if u == d: \n",
    "            path_tmp = np.zeros(shape=(self.V))\n",
    "            for i in range(len(path)-1):\n",
    "                # link_indice = list(G.todok().keys()).index((path[i], path[i+1]))\n",
    "                link_indice = graph_dict[path[i]][path[i+1]]\n",
    "                path_tmp[link_indice] = 1\n",
    "            if self.paths_m.shape[0]==0:\n",
    "                self.paths_m = path_tmp.reshape((1, self.V))\n",
    "            else:\n",
    "                self.paths_m = np.append(self.paths_m, path_tmp.reshape((1, self.V)), axis=0)\n",
    "        else: \n",
    "            # If current vertex is not destination \n",
    "            # Recur for all the vertices adjacent to this vertex \n",
    "            for i in self.graph[u]: \n",
    "                if visited[i]==False: \n",
    "                    self.printAllPathsUtil(i, d, visited, path, graph_dict) \n",
    "        # Remove current vertex from path[] and mark it as unvisited \n",
    "        path.pop()\n",
    "        visited[u]= False\n",
    "   \n",
    "   \n",
    "    # Prints all paths from 's' to 'd' \n",
    "    def printAllPaths(self,s, d, graph_dict): \n",
    "        self.paths_m = np.array([])\n",
    "        # Mark all the vertices as not visited \n",
    "        visited =[False]*(self.V)\n",
    "  \n",
    "        # Create an array to store paths \n",
    "        path = [] \n",
    "        \n",
    "        # Call the recursive helper function to print all paths \n",
    "        self.printAllPathsUtil(s, d,visited, path, graph_dict) \n",
    "        return self.paths_m \n",
    "\n",
    "def return_graph_dict(graph):\n",
    "    # graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "    graph_dict = {}\n",
    "    for i in range(graph.shape[0]):\n",
    "        try: \n",
    "            graph_dict[int(graph[i][1])]\n",
    "        except:\n",
    "            graph_dict[int(graph[i][1])] = {}\n",
    "        graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    return graph_dict\n",
    "    \n",
    "# argument graph\n",
    "def delta_matrix(graph, demand):\n",
    "    route2od = np.array([])\n",
    "    paths_matrix = np.array([])\n",
    "    graph_dict = return_graph_dict(graph)\n",
    "    g = Graph(graph.shape[0]) \n",
    "    for line in graph:\n",
    "        g.addEdge(int(line[1]), int(line[2]))\n",
    "\n",
    "    for i in range(demand.shape[0]):\n",
    "        s = int(demand[i][0]) ; d = int(demand[i][1])\n",
    "        paths_matrix_tmp = g.printAllPaths(s, d, graph_dict)\n",
    "        route2od_tmp = np.ones(paths_matrix_tmp.shape[0])\n",
    "        route2od_tmp = route2od_tmp*i\n",
    "        if paths_matrix.shape[0]==0:\n",
    "            paths_matrix = paths_matrix_tmp\n",
    "        else:\n",
    "            paths_matrix = np.append(paths_matrix, paths_matrix_tmp, axis=0)\n",
    "        route2od = np.append(route2od, route2od_tmp)\n",
    "    return paths_matrix, route2od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "max_float = sys.float_info.max\n",
    "if debug:\n",
    "    print(max_float)\n",
    "\n",
    "# TO DO ADD THE CAPACITY\n",
    "def travel_time(f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i] else float('inf') for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_travel_time(tt, G):\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "G = update_travel_time(travel_time(np.zeros(nb_links)), G) # , [1,1,-1,1,1]))\n",
    "# the following line make the matrix sparse, one can use G.toarray() to do the opposite\n",
    "G = scipy.sparse.csr_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta, route2od = delta_matrix(graph, demand)\n",
    "if debug:\n",
    "    print(delta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = travel_time(np.zeros(nb_links))\n",
    "delta_csr = scipy.sparse.csr_matrix(delta)\n",
    "if debug:\n",
    "    print((delta_csr @ tt))\n",
    "    print(np.argmin(delta_csr @ tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We upload the flow allocation \n",
    "#### 3.1 We compute the travel time of each path. \n",
    "#### 3.2 We compute the all or nothing allocation by putting all the demand on shortest paths.\n",
    "#### 3.3 We update the flow allocation with a bisection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t10.0\n"
     ]
    }
   ],
   "source": [
    "# check sparse vector\n",
    "h = scipy.sparse.lil_matrix(np.zeros(delta_csr.shape[0]))\n",
    "# the following is for one od\n",
    "demand[0][2] = 10\n",
    "# TO DO MODIFY TO TAKE INTO ACCOUNT SEVERALS OD\n",
    "h[:,0] = demand[0][2]\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: rewrite this function\n",
    "def potential(graph, f):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    links = int(np.max(graph[:, 0]) + 1)\n",
    "    g = np.copy(\n",
    "        graph.dot(np.diag([1., 1., 1., 1., 1 / 2., 1 / 3., 1 / 4., 1 / 5.])))\n",
    "    x = np.power(f.reshape((links, 1)), np.array([1, 2, 3, 4, 5]))\n",
    "    return np.sum(np.einsum('ij,ij->i', x, g[:, 3:]))\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if debug:\n",
    "            print(potential(graph, (1. - a) * f_tmp.toarray()[0] + a * f_aon.toarray()[0]))\n",
    "            print(l * d, end=\": \")\n",
    "            print(f(l * d))\n",
    "            print(r * d, end=\": \")\n",
    "            print(f(r * d))\n",
    "            print(str(m1 * d) + \" = \" + str(f(m1 * d)))\n",
    "            print(str(m2 * d) + \" = \" + str(f(m2 * d)))\n",
    "            print()\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "  (0, 0)\t1.0066659776071194\n",
      "  (0, 81)\t0.041058222655458936\n",
      "  (0, 82)\t0.061641663928456714\n",
      "  (0, 121)\t7.756863747158167\n",
      "  (0, 160)\t0.024620126347929774\n",
      "  (0, 161)\t0.005959519000975836\n",
      "  (0, 241)\t4.7666508869616896e-05\n",
      "  (0, 242)\t1.1031430767930204\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "nb_iter = 1000\n",
    "for i in range(nb_iter):\n",
    "    f = h @ delta_csr\n",
    "    tt_flow = travel_time(f.toarray()[0])\n",
    "    tt_p = delta_csr @ tt_flow\n",
    "    # the following is for one od\n",
    "    p_aon = np.argmin(tt_p)\n",
    "    if i % (nb_iter/20) == 0:\n",
    "        print(i)\n",
    "    if debug:\n",
    "        print(f.toarray()[0])\n",
    "        print(tt_flow)\n",
    "        print(tt_p)\n",
    "    # the following is for one od\n",
    "    # TO MODIFY TO TAKE INTO ACCOUNT SEVERAL ODs\n",
    "    h_aon = scipy.sparse.lil_matrix(np.zeros(delta_csr.shape[0]))\n",
    "    h_aon[:, p_aon] = demand[0][2]\n",
    "    f_aon = h_aon @ delta_csr\n",
    "    t = potential(graph, f.toarray()[0])\n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f.toarray()[0] + a * f_aon.toarray()[0]))\n",
    "    h = (1.-s)*h + s*h_aon\n",
    "    if debug:\n",
    "        print()\n",
    "        print(potential(graph,f.toarray()[0])-potential(graph, (1. - s) * f.toarray()[0] + s * f_aon.toarray()))\n",
    "        print(s)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h @ delta_csr\n",
    "tt_flow = travel_time(f.toarray()[0])\n",
    "tt_p = delta_csr @ tt_flow\n",
    "if debug:\n",
    "    print(tt_p[h.toarray()[0]!=0])\n",
    "    print(np.argsort(tt_p))\n",
    "    print(h!=0)\n",
    "    print(np.sort(tt_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    print(np.argsort(delta_csr @ tt_flow))\n",
    "    print((delta_csr @ tt_flow))\n",
    "    print(h.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
