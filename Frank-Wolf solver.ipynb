{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following problem (TAP-C):\n",
    "\\begin{align}\n",
    "\\min_{f, h} &\\sum_{a} \\int_{0}^{f_a} c_a(s)\\; \\text{d}s\n",
    "\\\\\n",
    "\\text{s.t.  } & \\;\\; f = \\Delta h\n",
    "\\\\\n",
    "& \\;\\; \n",
    "h \\geq 0\n",
    "\\\\\n",
    "& \\;\\; \n",
    "A h = d\n",
    "\\\\\n",
    "& \\;\\; \n",
    "f \\leq u\n",
    "\\end{align}\n",
    "\n",
    "This problem is hard to compute, even if it is a convex problem. Computing all the path of a network is NP-hard (with respect to the number of edges and links).\n",
    "\n",
    "Nevertheless, the TAP can be solve using a Frank-Wolf algorithm:\n",
    "\\begin{align}\n",
    "&\\text{1. TO DO }\n",
    "\\\\\n",
    "&\\text{2. }\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "First, we tried to solve the STA with CVX.\n",
    "This does not work because the values of the travel time are to big. \n",
    "\n",
    "Secondly, we solve the STA using links flow. \n",
    "This does not help us in our project because we need the path flow to compute the dual of the TAP-C.\n",
    "\n",
    "Thirdly, we solve the STA using paths flow. \n",
    "The issue here is that finding every path in a network in a NP-complete problem. \n",
    "But if we can compute every path (we only need to do it one time), then it is really fast to compute the shortest path. We do not need to do a Dikjstra's algorithm to compute the shortest path, only a big matrix multiplication and a array sorting are enough. This might be more difficult on a laptop. But it might be faster on a HPC.\n",
    "\n",
    "Finally, we solve the STA using links flow and we compute the paths during the all or nothing step of the Frank Wolf algorithm. TO BE DONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network = Brae\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We load the graph and the demand\n",
    "Both graph and demand are in csv file, we load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb nodes = 4\n",
      "nb links = 5\n",
      "nb ods = 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We need to demand to be an array like:\n",
    "[\n",
    "[o1, d1, demand from o1 to d1],\n",
    "...,\n",
    "[on, dn, demand from on to dn]\n",
    "]\n",
    "\n",
    "We need the graph to be an array like:\n",
    "[\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4],\n",
    "...,\n",
    "[id link n, node origin link n, node destination link n, a0, a1, a2, a3, a4]\n",
    "]\n",
    "where the node are indexed from 0 to nb_nodes-1,\n",
    "    the links are indexed from 0 to nb_links-1,\n",
    "    and a0, ..., a4 are the coeficient to calculate the travel time of one link as a function\n",
    "    of the flow on the link: t = a0 + a1 * f + a2 * f**2 + a3 * f**3 + a4 * f**4\n",
    "\n",
    "One can add some checks here to be sure that demand and graph respect this format!\n",
    "\n",
    "Some demand and graph data can be found on:\n",
    "    https://github.com/bstabler/TransportationNetworks\n",
    "    Here one need to perprocess the data before using this code\n",
    "\"\"\"\n",
    "\n",
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix (2d array)\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    return graph, demand\n",
    "\n",
    "graph, demand = cleaning_input(graph, demand)\n",
    "demand[0][2] = 10\n",
    "nb_links = int(np.max(graph[:,0])+1)\n",
    "nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "nb_ods = int(demand.shape[0])\n",
    "if debug:\n",
    "    print(\"nb nodes = \" + str(nb_nodes))\n",
    "    print(\"nb links = \" + str(nb_links))\n",
    "    print(\"nb ods = \" + str(nb_ods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the function which gives the travel time as a function of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000000.0\n"
     ]
    }
   ],
   "source": [
    "## Here Max float is fixed to not overlap the maximum float number when we compute the potential function\n",
    "max_float = 1e+10\n",
    "if debug:\n",
    "    print(max_float)\n",
    "\n",
    "\"\"\"\n",
    "We define the travel time of each link as a function of the flow on each link.\n",
    "This function is given by the network topology (in the graph file) and by the capacity of each link.\n",
    "One row of the graph is:\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4]\n",
    "Each row correspond to one link.\n",
    "The travel time of the link is t = a0 + a1 * f + a2 * f**2 + a3 * f**3 + a4 * f**4 if f < c \n",
    "    It is t = + inf (max_float) is f >= c\n",
    "\"\"\"\n",
    "def travel_time(graph, f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))]\n",
    "    # here we need to have the same indexation for graph and f. That why we need to store graph in a dictionnary\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i] else max_float for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We compute the all or nothing flow allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Dijkstra's algorithm class of scipy we need to define the adjacent matrix of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We store the travel time of each link in a sparce adjacency matrix G.\n",
    "Given a flow allocation f and a capacities constraints c, we compute \n",
    "the travel time of each link and store it in G.\n",
    "\n",
    "This allow us after to us the Disjtra's algorithm of the class scipy.sparse.csgraph\n",
    "\"\"\"\n",
    "\n",
    "def update_travel_time_from_tt(graph, tt):\n",
    "    G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "    G = scipy.sparse.lil_matrix(G)\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]\n",
    "    G = G.tocsr()\n",
    "    return G\n",
    "\n",
    "def update_travel_time_from_flow(graph, f, c=-1):\n",
    "    return update_travel_time_from_tt(graph, travel_time(graph, f, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t2.0\n",
      "  (1, 2)\t0.25\n",
      "  (1, 3)\t2.0\n",
      "  (2, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "G = update_travel_time_from_flow(graph, np.zeros(nb_links)) # , [1,1,-1,1,1]))\n",
    "if debug:\n",
    "    print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because the classic Frank Wolf algorithm does not take into account the paths,\n",
    "we need to store the path in memory. We do it by using Object and a dictionnary \n",
    "called paths_used.\n",
    "\n",
    "This idea is that we do not want to compute all the possible paths of the network\n",
    "before the beginning of the algorithm. So we compute the paths used during the algorithm,\n",
    "and we store them in memory.\n",
    "\n",
    "We build at the same time the incidence matrix.\n",
    "\n",
    "CAREFUL. We use the number of links of the graph in the calcul of the hash of every path.\n",
    "This variable should be a parameter.\n",
    "\"\"\"\n",
    "\n",
    "class path:\n",
    "    def __init__(self,links):\n",
    "        self.links = links\n",
    "        self.__flow = 0\n",
    "    def set_flow(self, flow):\n",
    "        self.__flow = flow\n",
    "    def get_flow(self,):\n",
    "        return self.__flow\n",
    "    def __eq__(self, other):\n",
    "        return np.all(self.links == other.links)\n",
    "    # I am not sure about the hash table structure in Python. I am used to Java.\n",
    "    def __hash__(self):\n",
    "        return hash(np.sum([hash(self.links[i]*(nb_links**i)) for i in range(len(self.links))]))\n",
    "    def __str__(self):\n",
    "        return str(self.__flow) + \" is on \" + str(self.links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{430: (<__main__.path object at 0x11061b9b0>, 0)}\n",
      "{430: (<__main__.path object at 0x11061b9b0>, 0), 405: (<__main__.path object at 0x11061bef0>, 0)}\n",
      "{430: (<__main__.path object at 0x11061b9b0>, 0), 405: (<__main__.path object at 0x11061bef0>, 0), 425: (<__main__.path object at 0x11061b240>, 0)}\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    paths_used = {}\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 1, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 0, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "print(demand[:,0])\n",
    "print(demand[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the all or nothing allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is the main point of the entire solver.\n",
    "It is the all or nothing allocation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "graph_dict = {}\n",
    "for i in range(graph.shape[0]):\n",
    "    try: \n",
    "        graph_dict[int(graph[i][1])]\n",
    "    except:\n",
    "        graph_dict[int(graph[i][1])] = {}\n",
    "    graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    \n",
    "# computing the all or nothing flow\n",
    "paths_used = {}\n",
    "\n",
    "# the all or nothing allocation\n",
    "# TO DO, PASS paths_used AS A PARAMETER OF THE FUNCTION\n",
    "def all_or_nothing():\n",
    "    # k is the next index to give to a new path.\n",
    "    global k\n",
    "    # paths_used_tmp is the set of the path in the all or nothing allocation of this step\n",
    "    paths_used_tmp = {}\n",
    "    # faon is the flow allocation of the all or nothing allocation\n",
    "    faon = np.zeros(nb_links)\n",
    "    \n",
    "    # using scipy to compute dijkstra\n",
    "    \"\"\"\n",
    "    HERE ONE CAN CHANGE THE ALGORITHM TO BE FASTER. IN THIS CASE WE DO NOT TAKE INTO ACCOUNT\n",
    "    THE SMALL NUMBER OF O-D PAIRS.\n",
    "    TO DO, ADD THE INDICE OF THE O-D PAIRS TO CONSIDER: \n",
    "    \n",
    "    indices : array_like or int, optional\n",
    "        if specified, only compute the paths for the points at the given indices.\n",
    "    \"\"\"\n",
    "    dist_matrix, return_predecessors = dijkstra(G, return_predecessors = True)\n",
    "    \n",
    "    # for every origin destination pairs (i.e. one line of the demand file)\n",
    "    for i in range(nb_ods):\n",
    "        o_tmp = int(demand[i][0])\n",
    "        d_tmp = int(demand[i][1])\n",
    "        flow_tmp = demand[i][2]\n",
    "\n",
    "        node_tmp = d_tmp\n",
    "        links = []\n",
    "        # using the dijkstra, we build the fastest path and we put the flow on it.\n",
    "        while node_tmp != o_tmp:\n",
    "            node_tmp_d = return_predecessors[o_tmp][node_tmp]\n",
    "            # Here we need the graph_dict to recover the link id from the nodes id.\n",
    "            link_tmp = graph_dict[node_tmp_d][node_tmp]\n",
    "            # we recover the path from the predecessor of the \n",
    "            links.insert(0, link_tmp)\n",
    "            faon[link_tmp] += flow_tmp\n",
    "            node_tmp = node_tmp_d\n",
    "        \n",
    "        p = path(links)\n",
    "        p.set_flow(flow_tmp)\n",
    "        \n",
    "        \n",
    "        if debug:\n",
    "            print(p)\n",
    "        # If we do not already know p, we add it to the delta matrix (here a dict)\n",
    "        if not hash(p) in paths_used:\n",
    "            if debug:\n",
    "                print(k)\n",
    "            # we add p and his index\n",
    "            paths_used[hash(p)] = (p, k)\n",
    "            paths_used_tmp[hash(p)] = (p, k)\n",
    "            k = k+1\n",
    "        else:\n",
    "            # we recover the index of p using the paths_used dict\n",
    "            paths_used_tmp[hash(p)] = (p, paths_used[hash(p)][1])\n",
    "    return faon, paths_used_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 is on [0, 2, 4]\n",
      "0\n",
      "{110: (<__main__.path object at 0x1106163c8>, 0)}\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    k = 0 \n",
    "    all_or_nothing()\n",
    "    print(paths_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function potential is used to compute the line search between \n",
    "the all or nothing allocation and the current flow allocation\n",
    "The function potential returns the objective function corresponding to\n",
    "the flow allocation f.\n",
    "\n",
    "The function line search does a 1D line search.\n",
    "\"\"\"\n",
    "\n",
    "def potential(graph, f, c=-1):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    pot_tmp = graph[:,3]*f + 1/2*graph[:,4]*(f**2) + 1/3*graph[:,5]*(f**3) + 1/4*graph[:,6]*(f**4) + 1/5*graph[:,7]*(f**5)\n",
    "    pot_tmp = [pot_tmp[i] if f[i]<c[i] else f[i]*max_float for i in range(len(f))]\n",
    "    return np.sum(pot_tmp)\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    debug_local = False\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if debug_local:\n",
    "            print(l * d, end=\": \")\n",
    "            print(f(l * d))\n",
    "            print(r * d, end=\": \")\n",
    "            print(f(r * d))\n",
    "            print(str(m1 * d) + \" = \" + str(f(m1 * d)))\n",
    "            print(str(m2 * d) + \" = \" + str(f(m2 * d)))\n",
    "            print()\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let run the Frank-Wolf's algorithm with a line search to find alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 is on [0, 2, 4]\n",
      "0\n",
      "[10.  0. 10.  0. 10.]\n",
      "{110: (<__main__.path object at 0x1106163c8>, 0)}\n",
      "0\n",
      "[10.]\n",
      "0\n",
      "10.0 is on [0, 3]\n",
      "1\n",
      "s: 0.25\n",
      "10.0 is on [1, 4]\n",
      "2\n",
      "s: 0.23529399885195756\n",
      "10.0 is on [0, 3]\n",
      "s: 0.06217553210787696\n",
      "10.0 is on [1, 4]\n",
      "s: 0.031249046210177656\n",
      "10.0 is on [0, 3]\n",
      "s: 0.01715394482308952\n",
      "10.0 is on [1, 4]\n",
      "s: 0.009800593138303839\n",
      "10.0 is on [0, 3]\n",
      "s: 0.00571951223841394\n",
      "10.0 is on [1, 4]\n",
      "s: 0.0033751800684811454\n",
      "10.0 is on [0, 3]\n",
      "s: 0.0020056720851240354\n",
      "10.0 is on [1, 4]\n",
      "s: 0.0011971555680325735\n",
      "10.0 is on [0, 3]\n",
      "s: 0.0007153823991146187\n",
      "10.0 is on [1, 4]\n",
      "s: 0.0004289150253953282\n",
      "10.0 is on [0, 3]\n",
      "s: 0.00025697052610951357\n",
      "10.0 is on [1, 4]\n",
      "s: 0.00015425682227032818\n",
      "10.0 is on [0, 3]\n",
      "s: 9.298324721385273e-05\n",
      "10.0 is on [1, 4]\n",
      "s: 5.5074693364078183e-05\n",
      "10.0 is on [0, 3]\n",
      "s: 3.147125335090182e-05\n",
      "10.0 is on [1, 4]\n",
      "s: 1.9788742747551364e-05\n",
      "10.0 is on [0, 3]\n",
      "s: 1.2874604635727729e-05\n",
      "10.0 is on [1, 4]\n",
      "s: 7.62939453125e-06\n",
      "10.0 is on [0, 3]\n",
      "s: 4.768372491526819e-06\n",
      "10.0 is on [1, 4]\n",
      "s: 2.861023858714319e-06\n",
      "10.0 is on [0, 3]\n",
      "s: 1.9073486328125e-06\n",
      "10.0 is on [1, 4]\n",
      "s: 0.0\n",
      "[5.00000853 2.49999853 2.49999294]\n"
     ]
    }
   ],
   "source": [
    "eps=1e-8\n",
    "k = 0\n",
    "paths_used = {}\n",
    "f = np.zeros(nb_links)\n",
    "G = update_travel_time_from_flow(graph, f)\n",
    "\n",
    "f, paths_aux = all_or_nothing()\n",
    "print(f)\n",
    "G = update_travel_time_from_flow(graph, f)\n",
    "print(paths_used)\n",
    "path_matrix = np.zeros(len(paths_aux))\n",
    "\n",
    "for val in paths_aux.values():\n",
    "    print(val[1])\n",
    "    path_matrix[val[1]] = val[0].get_flow()\n",
    "\n",
    "print(path_matrix)\n",
    "\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    faon, paths_tmp = all_or_nothing() \n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon))\n",
    "    print(\"s: \" + str(s))\n",
    "    if s < eps:\n",
    "        break\n",
    "    path_matrix = np.append(path_matrix, np.zeros(len(paths_used)-path_matrix.shape[0]))\n",
    "    path_matrix = (1-s) * path_matrix\n",
    "    for val in paths_tmp.values():\n",
    "        path_matrix[val[1]] += s * val[0].get_flow()\n",
    "    f = (1. - s) * f + s * faon\n",
    "    \n",
    "    # also update the path flow\n",
    "    ## TO DO ##\n",
    "    G = update_travel_time_from_flow(graph, f)\n",
    "print(path_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.000008529100963 is on [0, 2, 4]\n",
      "2.49999853134832 is on [0, 3]\n",
      "2.499992939550717 is on [1, 4]\n",
      "[[ 0.  3. 10.]]\n",
      "  (0, 1)\t1.7500007060449283\n",
      "  (0, 2)\t2.0\n",
      "  (1, 2)\t0.25\n",
      "  (1, 3)\t2.0\n",
      "  (2, 3)\t1.750000146865168\n",
      "[7.50000706 2.49999294 5.00000853 2.49999853 7.50000147]\n"
     ]
    }
   ],
   "source": [
    "for p in paths_used.values():\n",
    "    index = p[1]\n",
    "    p[0].set_flow(path_matrix[index])\n",
    "    print(str(p[0]))\n",
    "\n",
    "print(demand)\n",
    "print(G)\n",
    "print(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7500007060449283, 2.0, 0.25, 2.0, 1.750000146865168, \n"
     ]
    }
   ],
   "source": [
    "print(\"[\", end=\"\")\n",
    "for i in range(len(travel_time(graph, f))):\n",
    "    print(travel_time(graph, f)[i], end=\", \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   1.   1.   0.1  0.   0.   0.  ]\n",
      " [1.   0.   2.   2.   0.   0.   0.   0.  ]\n",
      " [2.   1.   2.   0.25 0.   0.   0.   0.  ]\n",
      " [3.   1.   3.   2.   0.   0.   0.   0.  ]\n",
      " [4.   2.   3.   1.   0.1  0.   0.   0.  ]]\n",
      "{110: (<__main__.path object at 0x1106163c8>, 0), 15: (<__main__.path object at 0x1106e64a8>, 1), 21: (<__main__.path object at 0x1106e62e8>, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "print(paths_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO DO: ADD THE CORRECT OUTPUT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
