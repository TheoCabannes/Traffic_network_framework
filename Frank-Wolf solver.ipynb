{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following problem (TAP-C):\n",
    "\\begin{align}\n",
    "\\min_{f, h} &\\sum_{a} \\int_{0}^{f_a} c_a(s)\\; \\text{d}s\n",
    "\\\\\n",
    "\\text{s.t.  } & \\;\\; f = \\Delta h\n",
    "\\\\\n",
    "& \\;\\; \n",
    "h \\geq 0\n",
    "\\\\\n",
    "& \\;\\; \n",
    "A h = d\n",
    "\\\\\n",
    "& \\;\\; \n",
    "f \\leq u\n",
    "\\end{align}\n",
    "\n",
    "This problem is hard to compute, even if it is a convex problem. Computing all the path of a network is NP-hard (with respect to the number of edges and links).\n",
    "\n",
    "Nevertheless, the TAP can be solve using a Frank-Wolf algorithm:\n",
    "\\begin{align}\n",
    "&\\text{1. TO DO }\n",
    "\\\\\n",
    "&\\text{2. }\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "First, we tried to solve the STA with CVX.\n",
    "This does not work because the values of the travel time are to big. \n",
    "\n",
    "Secondly, we solve the STA using links flow. \n",
    "This does not help us in our project because we need the path flow to compute the dual of the TAP-C.\n",
    "\n",
    "Thirdly, we solve the STA using paths flow. \n",
    "The issue here is that finding every path in a network in a NP-complete problem. \n",
    "But if we can compute every path (we only need to do it one time), then it is really fast to compute the shortest path. We do not need to do a Dikjstra's algorithm to compute the shortest path, only a big matrix multiplication and a array sorting are enough. This might be more difficult on a laptop. But it might be faster on a HPC.\n",
    "\n",
    "Finally, we solve the STA using links flow and we compute the paths during the all or nothing step of the Frank Wolf algorithm.\n",
    "\n",
    "TO DO: SOME CHANGE NEED TO BE DONE TO THE CAPACITY CONSTRAINTS. THE GRADIENT OF THE OBJECTIVE FUNCTION IS NOT FEASIBLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network_name = I210\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// let excute the cell 1 to 3\n",
       "Jupyter.notebook.execute_cells(Array.from({length: 3}, (x,i) => i+1))\n",
       "// let excute the cell 5 to 24\n",
       "Jupyter.notebook.execute_cells(Array.from({length: 20}, (x,i) => i+6))"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// let excute the cell 1 to 3\n",
    "Jupyter.notebook.execute_cells(Array.from({length: 3}, (x,i) => i+1))\n",
    "// let excute the cell 5 to 24\n",
    "Jupyter.notebook.execute_cells(Array.from({length: 20}, (x,i) => i+6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the network\n",
    "graph, demand = load_network(network_name)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We load the graph and the demand\n",
    "Both graph and demand are in csv file, we load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We need to demand to be an array like:\n",
    "[\n",
    "[o1, d1, demand from o1 to d1],\n",
    "...,\n",
    "[on, dn, demand from on to dn]\n",
    "]\n",
    "\n",
    "We need the graph to be an array like:\n",
    "[\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4],\n",
    "...,\n",
    "[id link n, node origin link n, node destination link n, a0, a1, a2, a3, a4]\n",
    "]\n",
    "where the node are indexed from 0 to nb_nodes-1,\n",
    "    the links are indexed from 0 to nb_links-1,\n",
    "    and a0, ..., a4 are the coeficient to calculate the travel time of one link as a function\n",
    "    of the flow on the link: t = a0 + a1 * f + a2 * f**2 + a3 * f**3 + a4 * f**4\n",
    "\n",
    "One can add some checks here to be sure that demand and graph respect this format!\n",
    "\n",
    "Some demand and graph data can be found on:\n",
    "    https://github.com/bstabler/TransportationNetworks\n",
    "    Here one need to perprocess the data before using this code\n",
    "\"\"\"\n",
    "\n",
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix (2d array)\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    # WE SHOULD ALSO CHECK THAT EVERY DEMAND IS WELL DEFINED: >0\n",
    "    return graph, demand\n",
    "\n",
    "def load_network(network):\n",
    "    graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "    demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)\n",
    "    graph, demand = cleaning_input(graph, demand)\n",
    "    if debug:\n",
    "        print(\"The network \" + network + \" has been charged. The network characteristics are:\")\n",
    "        nb_links = int(np.max(graph[:,0])+1)\n",
    "        nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "        nb_ods = int(demand.shape[0])\n",
    "        print(\"\\t nb nodes = \" + str(nb_nodes))\n",
    "        print(\"\\t nb links = \" + str(nb_links))\n",
    "        print(\"\\t nb ods = \" + str(nb_ods))\n",
    "    return graph, demand\n",
    "\n",
    "debug_local = False\n",
    "if debug_local:\n",
    "    graph, demand = load_network(network_name)\n",
    "    if network_name == Brae:\n",
    "        demand[0][2] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the function which gives the travel time as a function of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max capacity and to max travel time are 10000000000.0\n"
     ]
    }
   ],
   "source": [
    "## Here Max float is fixed to not overlap the maximum float number when we compute the potential function\n",
    "max_float = 1e+10\n",
    "float_appro = 1e-3\n",
    "if debug:\n",
    "    print(\"The max capacity and to max travel time are \" + str(max_float))\n",
    "\n",
    "\"\"\"\n",
    "We define the travel time of each link as a function of the flow on each link.\n",
    "This function is given by the network topology (in the graph file) and by the capacity of each link.\n",
    "One row of the graph is:\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4]\n",
    "Each row correspond to one link.\n",
    "The travel time of the link is t = a0 + a1 * f + a2 * f**2 + a3 * f**3 + a4 * f**4 if f < c \n",
    "    It is t = + inf (max_float) is f >= c\n",
    "\"\"\"\n",
    "def travel_time(graph, f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))]\n",
    "    # here we need to have the same indexation for graph and f. That why we need to store graph in a dictionnary\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    if len(c) != len(f):\n",
    "        print(\"ERROR: in travel_time(graph, f, c = -1)\\n******* the dimension of the capacity vector does not match the number of links *******\")\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i]-float_appro else max_float for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We compute the all or nothing flow allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Dijkstra's algorithm class of scipy we need to define the adjacent matrix of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We store the travel time of each link in a sparce adjacency matrix G.\n",
    "Given a flow allocation f and a capacities constraints c, we compute \n",
    "the travel time of each link and store it in G.\n",
    "\n",
    "This allow us after to us the Disjtra's algorithm of the class scipy.sparse.csgraph\n",
    "\"\"\"\n",
    "\n",
    "def update_travel_time_from_tt(graph, tt, nb_nodes):\n",
    "    G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "    G = scipy.sparse.lil_matrix(G)\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]\n",
    "    G = G.tocsr()\n",
    "    return G\n",
    "\n",
    "def update_travel_time_from_flow(graph, f, nb_nodes, c = -1):\n",
    "    return update_travel_time_from_tt(graph,travel_time(graph, f, c), nb_nodes)\n",
    "\n",
    "debug_local = False\n",
    "if debug_local:\n",
    "    graph, _ = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes) # , [1,1,-1,1,1]))\n",
    "    print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because the classic Frank Wolf algorithm does not take into account the paths,\n",
    "we need to store the path in memory. We do it by using Object and a dictionnary \n",
    "called paths_used.\n",
    "\n",
    "This idea is that we do not want to compute all the possible paths of the network\n",
    "before the beginning of the algorithm. So we compute the paths used during the algorithm,\n",
    "and we store them in memory.\n",
    "\n",
    "We build at the same time the incidence matrix.\n",
    "\n",
    "CAREFUL. We use the number of links of the graph in the calcul of the hash of every path.\n",
    "This variable should be a parameter.\n",
    "\"\"\"\n",
    "\n",
    "class path:\n",
    "    __nb_links = -1\n",
    "    def set_nb_links(nb_l):\n",
    "        path.__nb_links = nb_l\n",
    "    def __init__(self,links):\n",
    "        self.links = links\n",
    "        self.__flow = 0\n",
    "        if path.__nb_links == -1:\n",
    "            raise Exception('The number of links as not be defined inside the path class. We need it for defining the hash of a link. Please use the function path.set_nb_links(nb_links) to define it')\n",
    "    def set_flow(self, flow):\n",
    "        self.__flow = flow\n",
    "    def get_flow(self,):\n",
    "        return self.__flow\n",
    "    def __eq__(self, other):\n",
    "        return np.all(self.links == other.links)\n",
    "    # I am not sure about the hash table structure in Python. I am used to Java.\n",
    "    def __hash__(self):\n",
    "        return hash(np.sum([hash(self.links[i]*(path.__nb_links**i)) for i in range(len(self.links))]))\n",
    "    def __str__(self):\n",
    "        return str(self.__flow) + \" is on \" + str(self.links) \n",
    "\n",
    "debug_local = False\n",
    "if debug_local:\n",
    "    graph, _ = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    path.set_nb_links(nb_links)\n",
    "    paths_used = {}\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 1, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 0, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the all or nothing allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is the main point of the entire solver.\n",
    "It is the all or nothing allocation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "def build_graph_adjacency(graph):\n",
    "    graph_dict = {}\n",
    "    for i in range(graph.shape[0]):\n",
    "        try: \n",
    "            graph_dict[int(graph[i][1])]\n",
    "        except:\n",
    "            graph_dict[int(graph[i][1])] = {}\n",
    "        graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    return graph_dict\n",
    "\n",
    "def put_flow_on_short_path(faon, o_tmp, d_tmp, flow_tmp, return_predecessors, graph_dict, paths_used, paths_used_tmp, k, i, full_dijkstra):\n",
    "    node_tmp = d_tmp\n",
    "    links = []\n",
    "    # using the dijkstra, we build the fastest path and we put the flow on it.\n",
    "    while node_tmp != o_tmp:\n",
    "        if debug_local:\n",
    "            print(o_tmp)\n",
    "            print(node_tmp)\n",
    "        if not full_dijkstra:\n",
    "            node_tmp_d = return_predecessors[i][node_tmp]\n",
    "        else:\n",
    "            node_tmp_d = return_predecessors[o_tmp][node_tmp]\n",
    "        # Here we need the graph_dict to recover the link id from the nodes id.\n",
    "        link_tmp = graph_dict[node_tmp_d][node_tmp]\n",
    "        # we recover the path from the predecessor of the \n",
    "        links.insert(0, link_tmp)\n",
    "        faon[link_tmp] += flow_tmp\n",
    "        node_tmp = node_tmp_d\n",
    "\n",
    "    p = path(links)\n",
    "    p.set_flow(flow_tmp)\n",
    "\n",
    "\n",
    "    if debug_local:\n",
    "        print(p)\n",
    "    # If we do not already know p, we add it to the delta matrix (here a dict)\n",
    "    if not hash(p) in paths_used:\n",
    "        if debug_local:\n",
    "            print(k)\n",
    "        # we add p and his index\n",
    "        paths_used[hash(p)] = (p, k)\n",
    "        paths_used_tmp[hash(p)] = (p, k)\n",
    "        k = k+1\n",
    "    else:\n",
    "        # we recover the index of p using the paths_used dict\n",
    "        paths_used_tmp[hash(p)] = (p, paths_used[hash(p)][1])\n",
    "    return faon, paths_used, paths_used_tmp, k\n",
    "\n",
    "\n",
    "# computing the all or nothing flow\n",
    "def all_or_nothing(demand, G, graph_dict, paths_used, k, full_dijkstra = True):\n",
    "    # k is the next index to give to a new path.\n",
    "    \n",
    "    debug_local = False\n",
    "    # paths_used_tmp is the set of the path in the all or nothing allocation of this step\n",
    "    paths_used_tmp = {}\n",
    "    # faon is the flow allocation of the all or nothing allocation\n",
    "    nb_links = G.nnz\n",
    "    faon = np.zeros(nb_links)\n",
    "    \n",
    "    # using scipy to compute dijkstra\n",
    "    \"\"\"\n",
    "    HERE ONE CAN CHANGE THE ALGORITHM TO BE FASTER. WE MIGHT REWRITE THE DIJKSTRA ALGORITHM.\n",
    "    indices : array_like or int, optional\n",
    "        if specified, only compute the paths for the points at the given indices.\n",
    "    \"\"\"\n",
    "    indices = None\n",
    "    if not full_dijkstra:\n",
    "        indices = [int(demand[i,0]) for i in range(len(demand))]\n",
    "        \n",
    "    dist_matrix, return_predecessors = dijkstra(G, return_predecessors = True, indices = indices)\n",
    "    if debug_local:\n",
    "        print(return_predecessors)\n",
    "        print(indices)\n",
    "        \n",
    "    # for every origin destination pairs (i.e. one line of the demand file)\n",
    "    nb_ods = int(demand.shape[0])\n",
    "    for i in range(nb_ods):\n",
    "        # we compute the shortest path and add the demand on it.\n",
    "        o_tmp = int(demand[i][0])\n",
    "        d_tmp = int(demand[i][1])\n",
    "        flow_tmp = demand[i][2]\n",
    "        faon, paths_used, paths_used_tmp, k = put_flow_on_short_path(faon, o_tmp, d_tmp, flow_tmp, return_predecessors, graph_dict, paths_used, paths_used_tmp, k, i, full_dijkstra)\n",
    "\n",
    "    return faon, paths_used_tmp, paths_used, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_local = False\n",
    "if debug_local:\n",
    "    # we load the network\n",
    "    graph, demand = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    print(nb_links)\n",
    "    path.set_nb_links(nb_links)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes)\n",
    "    graph_dict = build_graph_adjacency(graph)\n",
    "    paths_used = {}\n",
    "    k = 0 \n",
    "    _, _ , pp, k = all_or_nothing(demand, G, graph_dict, paths_used, k)\n",
    "    for p in pp.values():\n",
    "        print(p[0])\n",
    "    all_or_nothing(demand, G, graph_dict, paths_used, k, False)\n",
    "    for p in paths_used.values():\n",
    "        print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function potential is used to compute the line search between \n",
    "the all or nothing allocation and the current flow allocation\n",
    "The function potential returns the objective function corresponding to\n",
    "the flow allocation f.\n",
    "\n",
    "The function line search does a 1D line search.\n",
    "\"\"\"\n",
    "\n",
    "def potential(graph, f, c=-1):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    pot_tmp = graph[:,3]*f + 1/2*graph[:,4]*(f**2) + 1/3*graph[:,5]*(f**3) + 1/4*graph[:,6]*(f**4) + 1/5*graph[:,7]*(f**5)\n",
    "    pot_tmp = [pot_tmp[i] if f[i]<c[i] else f[i]*max_float for i in range(len(f))]\n",
    "    return np.sum(pot_tmp)\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    debug_local = False\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if debug_local:\n",
    "            print(l * d, end=\": \")\n",
    "            print(f(l * d))\n",
    "            print(r * d, end=\": \")\n",
    "            print(f(r * d))\n",
    "            print(str(m1 * d) + \" = \" + str(f(m1 * d)))\n",
    "            print(str(m2 * d) + \" = \" + str(f(m2 * d)))\n",
    "            print()\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let run the Frank-Wolf's algorithm with a line search to find alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network data/I210 has been charged. The network characteristics are:\n",
      "\t nb nodes = 20\n",
      "\t nb links = 41\n",
      "\t nb ods = 1\n",
      "  (0, 1)\t1.38\n",
      "  (0, 6)\t1.15\n",
      "  (1, 2)\t1.38\n",
      "  (1, 7)\t1.14\n",
      "  (2, 3)\t1.68\n",
      "  (2, 8)\t1.13\n",
      "  (3, 4)\t1.26\n",
      "  (3, 9)\t1.05\n",
      "  (4, 5)\t2.25\n",
      "  (4, 10)\t1.04\n",
      "  (5, 11)\t1.09\n",
      "  (6, 0)\t1.15\n",
      "  (6, 7)\t0.48\n",
      "  (6, 12)\t0.36\n",
      "  (7, 1)\t1.14\n",
      "  (7, 8)\t0.48\n",
      "  (7, 13)\t0.39\n",
      "  (8, 2)\t1.13\n",
      "  (8, 9)\t0.58\n",
      "  (8, 14)\t0.38\n",
      "  (9, 3)\t1.05\n",
      "  (9, 10)\t0.43\n",
      "  (9, 15)\t0.48\n",
      "  (10, 4)\t1.04\n",
      "  (10, 11)\t0.77\n",
      "  (10, 16)\t0.5\n",
      "  (11, 5)\t1.09\n",
      "  (11, 17)\t0.47\n",
      "  (11, 19)\t0.22\n",
      "  (12, 6)\t0.36\n",
      "  (12, 13)\t1.38\n",
      "  (13, 7)\t0.39\n",
      "  (13, 14)\t1.38\n",
      "  (14, 8)\t0.38\n",
      "  (14, 15)\t1.68\n",
      "  (15, 9)\t0.48\n",
      "  (15, 16)\t1.25\n",
      "  (16, 10)\t0.5\n",
      "  (16, 17)\t2.22\n",
      "  (17, 11)\t0.47\n",
      "  (18, 6)\t0.29\n",
      "[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0. 25000.     0.     0. 25000.     0.     0. 25000.     0.\n",
      "     0. 25000.     0.     0. 25000.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0. 25000.\n",
      " 25000.]\n",
      "Test of initialization_FW\n",
      "[    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.     0. 25000.     0.     0. 25000.     0.     0. 25000.     0.\n",
      "     0. 25000.     0.     0. 25000.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0. 25000.\n",
      " 25000.]\n",
      "25000.0 is on [40, 12, 15, 18, 21, 24, 39]\n",
      "[25000.]\n",
      "Iteration: 0\n",
      "s: 0.13017301136669227\n",
      "The paths used at this iteration are:\n",
      "25000.0 is on [40, 13, 29, 31, 33, 35, 37, 38, 39]\n",
      "Iteration: 100\n",
      "s: 7.796287695782818e-05\n",
      "The paths used at this iteration are:\n",
      "25000.0 is on [40, 12, 15, 18, 22, 35, 36, 24, 39]\n",
      "[1.89522781e+04 2.70002298e+03 2.58494790e+03 1.79501481e+02\n",
      " 8.98800319e+01 4.61496980e+01 2.55162433e+01 2.34910714e+01\n",
      " 3.87494869e+01 1.06487565e+01 3.41884806e+01 1.79223420e+01\n",
      " 1.62334098e+01 1.86106002e+01 3.09289082e+01 1.17248706e+01\n",
      " 1.31311598e+01 1.22192118e+01 1.12021600e+01 8.85574914e+00\n",
      " 1.52706640e+01 1.00187094e+01 4.71225851e+00 1.43751400e+01\n",
      " 9.24551061e+00 1.25396841e+01 3.02459736e+00 6.26377730e+00\n",
      " 5.60774001e+00 5.79340731e+00 6.72337139e+00 5.38516054e+00\n",
      " 3.71088269e+00 3.52440589e+00 7.65455800e+00 6.30487676e+00\n",
      " 2.22635424e+00 1.01896929e+01 1.93035283e+00 2.40982164e+00\n",
      " 2.82955568e+00 1.85395444e+00 2.89957007e+00 1.84744030e+00\n",
      " 2.37873133e+00 3.63812712e+00 3.28993054e+00 7.83460174e-01\n",
      " 1.33356281e+00 6.83012183e-01 7.84068512e-01 1.64684643e+00\n",
      " 6.83510521e-01 1.87629441e+00 2.00872974e+00 1.48756938e+00\n",
      " 9.67029550e-01 4.72937602e-01 6.45800487e-01 3.51095214e-01\n",
      " 5.35707422e-01 2.14303377e-01 5.17996897e-01 4.04940537e-01\n",
      " 4.04947102e-01 5.59954082e-01 4.52750682e-01 2.14422621e-01\n",
      " 3.69333016e-01 2.14472083e-01 1.90688359e-01 1.54935263e-01\n",
      " 9.53459526e-02 9.53629808e-02]\n",
      "74\n",
      "[1.47875936e+14 1.15000000e+00 2.46559670e+14 1.14000000e+00\n",
      " 2.98508088e+14 1.04677362e+08 2.21682961e+14 1.75988032e+08\n",
      " 2.85479656e+14 2.11692237e+10 1.38299033e+14 1.23229946e+14\n",
      " 2.70765706e+14 5.60199193e+13 4.22031035e+10 2.46598726e+14\n",
      " 1.00510337e+09 8.47706795e+07 2.98489150e+14 4.29755423e+07\n",
      " 1.26596872e+08 2.21688297e+14 1.66074331e+07 7.42348541e+07\n",
      " 4.23778201e+14 1.45535093e+08 1.09000000e+00 4.70000000e-01\n",
      " 3.60000000e-01 2.14743024e+14 4.06229351e+07 2.46603729e+14\n",
      " 5.24245782e+07 2.98491558e+14 1.80510271e+07 2.21699239e+14\n",
      " 1.58155057e+09 3.49734375e+14 7.40428631e+13 3.30000000e+14\n",
      " 4.35000000e+14]\n",
      "  (0, 12)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 39)\t1.0\n",
      "  (0, 40)\t1.0\n",
      "  (1, 13)\t1.0\n",
      "  (1, 29)\t1.0\n",
      "  (1, 31)\t1.0\n",
      "  (1, 33)\t1.0\n",
      "  (1, 35)\t1.0\n",
      "  (1, 37)\t1.0\n",
      "  (1, 38)\t1.0\n",
      "  (1, 39)\t1.0\n",
      "  (1, 40)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (2, 11)\t1.0\n",
      "  (2, 39)\t1.0\n",
      "  (2, 40)\t1.0\n",
      "  :\t:\n",
      "  (71, 36)\t1.0\n",
      "  (71, 39)\t1.0\n",
      "  (71, 40)\t1.0\n",
      "  (72, 12)\t1.0\n",
      "  (72, 16)\t1.0\n",
      "  (72, 18)\t1.0\n",
      "  (72, 21)\t1.0\n",
      "  (72, 25)\t1.0\n",
      "  (72, 31)\t1.0\n",
      "  (72, 32)\t1.0\n",
      "  (72, 37)\t1.0\n",
      "  (72, 38)\t1.0\n",
      "  (72, 39)\t1.0\n",
      "  (72, 40)\t1.0\n",
      "  (73, 12)\t1.0\n",
      "  (73, 16)\t1.0\n",
      "  (73, 18)\t1.0\n",
      "  (73, 22)\t1.0\n",
      "  (73, 24)\t1.0\n",
      "  (73, 31)\t1.0\n",
      "  (73, 32)\t1.0\n",
      "  (73, 35)\t1.0\n",
      "  (73, 36)\t1.0\n",
      "  (73, 39)\t1.0\n",
      "  (73, 40)\t1.0\n",
      "[2.22632008e+15 2.22633471e+15 2.22663529e+15 2.22635800e+15\n",
      " 2.22634102e+15 2.22635718e+15 2.22633725e+15 2.22634234e+15\n",
      " 2.22632614e+15 2.22633251e+15 2.22633604e+15 2.22633304e+15\n",
      " 2.22634590e+15 2.22632580e+15 2.22633262e+15 2.22633984e+15\n",
      " 2.22631654e+15 2.22633822e+15 2.22634032e+15 2.22635182e+15\n",
      " 2.22632064e+15 2.22633460e+15 2.22634128e+15 2.22633781e+15\n",
      " 2.22631736e+15 2.22631926e+15 2.22631861e+15 2.22633655e+15\n",
      " 2.22633576e+15 2.22634534e+15 2.22633851e+15 2.22635272e+15\n",
      " 2.22634366e+15 2.22633587e+15 2.22633989e+15 2.22635544e+15\n",
      " 2.22634447e+15 2.22633928e+15 2.22633315e+15 2.22632908e+15\n",
      " 2.22632061e+15 2.22633657e+15 2.22631836e+15 2.22635533e+15\n",
      " 2.22633505e+15 2.22633848e+15 2.22632333e+15 2.22631783e+15\n",
      " 2.22633153e+15 2.22633847e+15 2.22632311e+15 2.22635446e+15\n",
      " 2.22633008e+15 2.22632255e+15 2.22633929e+15 2.22632498e+15\n",
      " 2.22632237e+15 2.22633318e+15 2.22633732e+15 2.22632173e+15\n",
      " 2.22631264e+15 2.22634655e+15 2.22635467e+15 2.22635157e+15\n",
      " 2.22632108e+15 2.22632003e+15 2.22635234e+15 2.22632851e+15\n",
      " 2.22632251e+15 2.22634158e+15 2.22635641e+15 2.22633887e+15\n",
      " 2.22632532e+15 2.22633868e+15]\n",
      "[(18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19), (18, 19)]\n",
      "(74, 41)\n"
     ]
    }
   ],
   "source": [
    "def build_network(graph, c):\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    path.set_nb_links(nb_links)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes, c)\n",
    "    graph_dict = build_graph_adjacency(graph)\n",
    "    return nb_links, nb_nodes, G, graph_dict\n",
    "    \n",
    "def initialization_FW(demand, G, graph_dict, all_paths_used, k, graph, nb_nodes, c):\n",
    "    debug_local = True\n",
    "    print(G)\n",
    "    f, paths_used_for_this_iter, all_paths_used, k = all_or_nothing(demand, G, graph_dict, all_paths_used, k)\n",
    "    \n",
    "    print(f)\n",
    "    G = update_travel_time_from_flow(graph, f, nb_nodes, c)\n",
    "    path_flow_matrix = np.zeros(k)\n",
    "    for val in paths_used_for_this_iter.values():\n",
    "        path_flow_matrix[val[1]] = val[0].get_flow()\n",
    "\n",
    "    if debug_local:\n",
    "        print(\"Test of initialization_FW\")\n",
    "        print(f)\n",
    "        for p in paths_used_for_this_iter.values():\n",
    "            print(p[0])\n",
    "        print(path_flow_matrix)\n",
    "    return f, paths_used_for_this_iter, all_paths_used, k, G, path_flow_matrix\n",
    "\n",
    "def iteration_FW(demand, G, graph_dict, all_paths_used, k, graph, f, nb_nodes, c, path_flow_matrix, i):\n",
    "    # WE COMPUTE THE ALL OR NOTHING ALGORITHM\n",
    "    faon, paths_used_for_this_iter, all_paths_used, k = all_or_nothing(demand, G, graph_dict, all_paths_used, k)\n",
    "\n",
    "    # we find the better convex combinaison of f and faon\n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon, c))\n",
    "    # TO DO\n",
    "    # HERE WE SHOULD BE CAREFUL IN THE CASE WHERE WE HAVE THE CAPACITY CONSTRAINTS\n",
    "    # THE GRADIENT OF THE FUNCTION IS NOT THE SHORTEST PATH\n",
    "    # WE SHOULD REMOVE THE PATH THAT SATURATED THE LINKS\n",
    "    # AND THEN COMPUTE THE SOLUTION WITHOUT THE SATURATION, AND WITHOUT THE \n",
    "    # CORRESPONDING DEMAND\n",
    "    f = (1. - s) * f + s * faon\n",
    "    G = update_travel_time_from_flow(graph, f, nb_nodes, c)\n",
    "\n",
    "    \"\"\"\n",
    "    HERE I SHOULD MEMORIZED ALL THE PATH THAT PUT FLOW TO THE CAPACITY AND DO NOT CHANGE THEM IN THE LINE SEARCH.\n",
    "    \"\"\"\n",
    "    # we multiply the previous path flow matrix by the coeficient of the line search\n",
    "    path_flow_matrix = (1-s) * path_flow_matrix\n",
    "    # we add the new path at the end of the path flow matrix.\n",
    "    path_flow_matrix = np.append(path_flow_matrix, np.zeros(len(all_paths_used)-path_flow_matrix.shape[0]))\n",
    "    # we add the all or nothing path flow (mulitply by the coeficient of the line search) to the path flow matrix.\n",
    "    for val in paths_used_for_this_iter.values():\n",
    "        # val[1] is the index of the path, val[0] is the path object\n",
    "        path_flow_matrix[val[1]] += s * val[0].get_flow()\n",
    "\n",
    "    if debug and i % (nb_iter / 10) == 0:\n",
    "        print(\"Iteration: \" + str(i))\n",
    "        print(\"s: \" + str(s))\n",
    "        print(\"The paths used at this iteration are:\")\n",
    "        for p in paths_used_for_this_iter.values():\n",
    "            print(p[0])\n",
    "    return path_flow_matrix, f, G, all_paths_used, k, s\n",
    "\n",
    "def output_FW(all_paths_used, nb_links, graph, f, demand):\n",
    "    # MAYBE I SHOULD SPLIT THE CODE HERE TO MAKE EASIER TEST\n",
    "    # At the end we do some work to return a proper output\n",
    "    nb_paths = len(all_paths_used.keys())\n",
    "    delta = np.zeros(shape=(nb_paths, nb_links)) # nb_links should be a parameter\n",
    "    route2od = [0 for _ in range(nb_paths)]# np.zeros(shape=nb_paths)\n",
    "    delta = scipy.sparse.lil_matrix(delta)\n",
    "    tt_f = np.array(travel_time(graph, f))\n",
    "\n",
    "    for p in all_paths_used.values():\n",
    "        # here I can built route2od matrix at the same time\n",
    "        try:\n",
    "            links_tmp = p[0].links\n",
    "            for l in links_tmp:\n",
    "                delta[p[1],l] = 1\n",
    "            route2od[p[1]] = (int(graph[int(links_tmp[0])][1]), int(graph[int(links_tmp[-1])][2]))\n",
    "        except:\n",
    "            ;\n",
    "    delta = delta.tocsr()\n",
    "    # I should built the route2od matrix here,\n",
    "    # route2od should be build from the all_paths_used_dict\n",
    "    return tt_f, delta, route2od\n",
    "\n",
    "def Frank_Wolf_solver(graph, demand, eps, nb_iter, c=-1):\n",
    "    ######### FIRST, WE INITIALIZE THE ALGORITHM #########\n",
    "    # We initialize the number of paths_used to 0, \n",
    "    k = 0\n",
    "    all_paths_used = {}\n",
    "    \n",
    "    # we built the network as a matrix from the graph file\n",
    "    nb_links, nb_nodes, G, graph_dict = build_network(graph, c)\n",
    "    \n",
    "    # The initialization step: we put all the demand on the fastest free flow travel time paths.\n",
    "    f, paths_used_for_this_iter, all_paths_used, k, G, path_flow_matrix = initialization_FW(demand, G, graph_dict, all_paths_used, k, graph, nb_nodes, c)\n",
    "\n",
    "    ######### THEN, I RUN THE ITERATION OF THE FRANK-WOLF ALGORITHM #########\n",
    "    for i in range(nb_iter):\n",
    "        path_flow_matrix, f, G, all_paths_used, k, s = iteration_FW(demand, G, graph_dict, all_paths_used, k, graph, f, nb_nodes, c, path_flow_matrix, i)\n",
    "        if s < eps:\n",
    "            break\n",
    "    if debug:\n",
    "        print(path_flow_matrix)\n",
    "       \n",
    "    ######### FINALLY, I WORK ON THE OUTPUT TO RETURN #########\n",
    "    tt_f, delta, route2od = output_FW(all_paths_used, nb_links, graph, f, demand)\n",
    "    return path_flow_matrix, tt_f, delta, route2od\n",
    "\n",
    "eps=1e-8\n",
    "nb_iter = 1000\n",
    "graph, demand = load_network(network_name)\n",
    "if network_name == Brae:\n",
    "    demand[0][2] = 10\n",
    "        \n",
    "path_flow_matrix, tt_f, delta, route2od = Frank_Wolf_solver(graph, demand, eps, nb_iter) #, [11,11,2,11,11])\n",
    "\n",
    "if debug:\n",
    "    nb_paths = len(path_flow_matrix)\n",
    "    print(nb_paths)\n",
    "    print(tt_f)\n",
    "    print(delta)\n",
    "    print(delta @ tt_f)\n",
    "    print(route2od)\n",
    "    print(delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 19)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]\n",
      "[2.22632008e+15 2.22633471e+15 2.22663529e+15 2.22635800e+15\n",
      " 2.22634102e+15 2.22635718e+15 2.22633725e+15 2.22634234e+15\n",
      " 2.22632614e+15 2.22633251e+15 2.22633604e+15 2.22633304e+15\n",
      " 2.22634590e+15 2.22632580e+15 2.22633262e+15 2.22633984e+15\n",
      " 2.22631654e+15 2.22633822e+15 2.22634032e+15 2.22635182e+15\n",
      " 2.22632064e+15 2.22633460e+15 2.22634128e+15 2.22633781e+15\n",
      " 2.22631736e+15 2.22631926e+15 2.22631861e+15 2.22633655e+15\n",
      " 2.22633576e+15 2.22634534e+15 2.22633851e+15 2.22635272e+15\n",
      " 2.22634366e+15 2.22633587e+15 2.22633989e+15 2.22635544e+15\n",
      " 2.22634447e+15 2.22633928e+15 2.22633315e+15 2.22632908e+15\n",
      " 2.22632061e+15 2.22633657e+15 2.22631836e+15 2.22635533e+15\n",
      " 2.22633505e+15 2.22633848e+15 2.22632333e+15 2.22631783e+15\n",
      " 2.22633153e+15 2.22633847e+15 2.22632311e+15 2.22635446e+15\n",
      " 2.22633008e+15 2.22632255e+15 2.22633929e+15 2.22632498e+15\n",
      " 2.22632237e+15 2.22633318e+15 2.22633732e+15 2.22632173e+15\n",
      " 2.22631264e+15 2.22634655e+15 2.22635467e+15 2.22635157e+15\n",
      " 2.22632108e+15 2.22632003e+15 2.22635234e+15 2.22632851e+15\n",
      " 2.22632251e+15 2.22634158e+15 2.22635641e+15 2.22633887e+15\n",
      " 2.22632532e+15 2.22633868e+15]\n"
     ]
    }
   ],
   "source": [
    "def check_wardrop(j, demand, route2od, delta, path_flow_matrix, tt_f):\n",
    "    f = delta.T @ path_flow_matrix\n",
    "    tt_p = delta @ tt_f\n",
    "    od = (int(demand[j][0]), int(demand[j][1]))\n",
    "    tab = []\n",
    "    for i in range(len(route2od)):\n",
    "        if route2od[i] == od:\n",
    "            tab.append(i)\n",
    "    print(od)\n",
    "    print(tab)\n",
    "    print(tt_p[tab])\n",
    "check_wardrop(0, demand, route2od, delta, path_flow_matrix, tt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
