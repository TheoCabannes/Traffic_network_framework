{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following problem (TAP-C):\n",
    "\\begin{align}\n",
    "\\min_{f, h} &\\sum_{a} \\int_{0}^{f_a} c_a(s)\\; \\text{d}s\n",
    "\\\\\n",
    "\\text{s.t.  } & \\;\\; f = \\Delta h\n",
    "\\\\\n",
    "& \\;\\; \n",
    "h \\geq 0\n",
    "\\\\\n",
    "& \\;\\; \n",
    "A h = d\n",
    "\\\\\n",
    "& \\;\\; \n",
    "f \\leq u\n",
    "\\end{align}\n",
    "\n",
    "This problem is hard to compute, even if it is a convex problem. Computing all the path of a network is NP-hard (with respect to the number of edges and links).\n",
    "\n",
    "Nevertheless, the TAP can be solve using a Frank-Wolf algorithm:\n",
    "\\begin{align}\n",
    "&\\text{1. TO DO }\n",
    "\\\\\n",
    "&\\text{2. }\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "First, we tried to solve the STA with CVX.\n",
    "This does not work because the values of the travel time are to big. \n",
    "\n",
    "Then, we solves the STA using links flow. \n",
    "This does not help us in our project because we need the path flow to compute the dual of the TAP-C.\n",
    "\n",
    "Finally, we solve the STA using paths flow.\n",
    "The issue here is that finding every path in a network in a NP-complete problem.\n",
    "But if we can compute every path (we only need to do it one time), then it is really fast to compute the shortest path. We do not need to do a Dikjstra's algorithm to compute the shortest path, only a big matrix multiplication and a array sorting are enough. This might be more difficult on a laptop. But it might be faster on a HPC.\n",
    "\n",
    "An other possibility, would be to compute the paths during the Frank Wolf's algorithm. THIS HAS TO BE DONE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. We load and clean the network and the demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network = I210\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb nodes = 20\n",
      "nb links = 41\n",
      "nb ods = 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We need to demand to be an array like:\n",
    "[\n",
    "[o1, d1, demand from o1 to d1],\n",
    "...,\n",
    "[on, dn, demand from on to dn]\n",
    "]\n",
    "\n",
    "We need the graph to be an array like:\n",
    "[\n",
    "[id link 1, node origin link 1, node destination link 1, a1, a2, a3, a4],\n",
    "...,\n",
    "[id link n, node origin link n, node destination link n, a1, a2, a3, a4]\n",
    "]\n",
    "where the node are indexed from 0 to nb_nodes-1,\n",
    "    the links are indexed from 0 to nb_links-1\n",
    "\n",
    "One can add some checks here to be sure that demand and graph respect this format!\n",
    "\"\"\"\n",
    "\n",
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix (2d array)\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    return graph, demand\n",
    "\n",
    "graph, demand = cleaning_input(graph, demand)\n",
    "nb_links = int(np.max(graph[:,0])+1)\n",
    "nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "nb_ods = int(demand.shape[0])\n",
    "if debug:\n",
    "    print(\"nb nodes = \" + str(nb_nodes))\n",
    "    print(\"nb links = \" + str(nb_links))\n",
    "    print(\"nb ods = \" + str(nb_ods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. We compute the incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We need to define 2 matrix called path_matrix (or delta) and route2od which gives are:\n",
    "- delta is the incidence matrix. Each row of delta is a path, each column a link.\n",
    "    delta[i][j] is 1 if the link j is used by the path i, 0 otherwise\n",
    "- route2od is the array which recover the origin and destination of every path\n",
    "    route2od[i] is the indice of the line which codes the origin and the demand\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict \n",
    "   \n",
    "# This class represents a directed graph  \n",
    "# using adjacency list representation \n",
    "class Graph: \n",
    "   \n",
    "    def __init__(self,vertices): \n",
    "        #No. of vertices \n",
    "        self.V= vertices  \n",
    "        # default dictionary to store graph \n",
    "        self.graph = defaultdict(list)  \n",
    "   \n",
    "    # function to add an edge to graph \n",
    "    def addEdge(self,u,v): \n",
    "        self.graph[u].append(v) \n",
    "   \n",
    "    def printAllPathsUtil(self, u, d, visited, path, graph_dict): \n",
    "        # Mark the current node as visited and store in path \n",
    "        visited[u]= True\n",
    "        path.append(u) \n",
    "        \n",
    "        if u == d: \n",
    "            path_tmp = np.zeros(shape=(self.V))\n",
    "            for i in range(len(path)-1):\n",
    "                # link_indice = list(G.todok().keys()).index((path[i], path[i+1]))\n",
    "                link_indice = graph_dict[path[i]][path[i+1]]\n",
    "                path_tmp[link_indice] = 1\n",
    "            if self.paths_m.shape[0]==0:\n",
    "                self.paths_m = path_tmp.reshape((1, self.V))\n",
    "            else:\n",
    "                self.paths_m = np.append(self.paths_m, path_tmp.reshape((1, self.V)), axis=0)\n",
    "        else: \n",
    "            # If current vertex is not destination \n",
    "            # Recur for all the vertices adjacent to this vertex \n",
    "            for i in self.graph[u]: \n",
    "                if visited[i]==False: \n",
    "                    self.printAllPathsUtil(i, d, visited, path, graph_dict) \n",
    "        # Remove current vertex from path[] and mark it as unvisited \n",
    "        path.pop()\n",
    "        visited[u]= False\n",
    "   \n",
    "   \n",
    "    # Prints all paths from 's' to 'd' \n",
    "    def printAllPaths(self,s, d, graph_dict): \n",
    "        self.paths_m = np.array([])\n",
    "        # Mark all the vertices as not visited \n",
    "        visited =[False]*(self.V)\n",
    "  \n",
    "        # Create an array to store paths \n",
    "        path = [] \n",
    "        \n",
    "        # Call the recursive helper function to print all paths \n",
    "        self.printAllPathsUtil(s, d, visited, path, graph_dict) \n",
    "        return self.paths_m \n",
    "\n",
    "def return_graph_dict(graph):\n",
    "    # graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "    graph_dict = {}\n",
    "    for i in range(graph.shape[0]):\n",
    "        try: \n",
    "            graph_dict[int(graph[i][1])]\n",
    "        except:\n",
    "            graph_dict[int(graph[i][1])] = {}\n",
    "        graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    return graph_dict\n",
    "    \n",
    "# argument graph\n",
    "def delta_matrix(graph, demand):\n",
    "    route2od = np.array([])\n",
    "    paths_matrix = np.array([])\n",
    "    graph_dict = return_graph_dict(graph)\n",
    "    g = Graph(graph.shape[0]) \n",
    "    for line in graph:\n",
    "        g.addEdge(int(line[1]), int(line[2]))\n",
    "\n",
    "    for i in range(demand.shape[0]):\n",
    "        s = int(demand[i][0]) ; d = int(demand[i][1])\n",
    "        paths_matrix_tmp = g.printAllPaths(s, d, graph_dict)\n",
    "        route2od_tmp = np.ones(paths_matrix_tmp.shape[0])\n",
    "        route2od_tmp = route2od_tmp*i\n",
    "        if paths_matrix.shape[0]==0:\n",
    "            paths_matrix = paths_matrix_tmp\n",
    "        else:\n",
    "            paths_matrix = np.append(paths_matrix, paths_matrix_tmp, axis=0)\n",
    "        route2od = np.append(route2od, route2od_tmp)\n",
    "    return paths_matrix, route2od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We define the travel time function. We encode the capacity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000000.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "max_float = 1e+10\n",
    "if debug:\n",
    "    print(max_float)\n",
    "\n",
    "# TO DO ADD THE CAPACITY\n",
    "def travel_time(f, c = -1):\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    tt_tmp = graph[:,3] + graph[:,4]*f + graph[:,5]*(f**2) + graph[:,6]*(f**3) + graph[:,7]*(f**4)\n",
    "    tt_tmp = [tt_tmp[i] if f[i]<c[i] else max_float for i in range(len(f))]\n",
    "    return tt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_travel_time(tt, G):\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "G = update_travel_time(travel_time(np.zeros(nb_links)), G) # , [1,1,-1,1,1]))\n",
    "# the following line make the matrix sparse, one can use G.toarray() to do the opposite\n",
    "G = scipy.sparse.csr_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243, 41)\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "delta, route2od = delta_matrix(graph, demand)\n",
    "if debug:\n",
    "    print(delta.shape)\n",
    "    print(delta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.7   9.17 11.59 11.96  8.35 10.77 13.76 10.15 11.57 11.78 10.25 12.67\n",
      " 10.94  7.33  9.75 12.74  9.13 10.55 13.74 12.21 14.63 12.9   9.29 11.71\n",
      " 13.74 10.13 11.55 12.07 10.54 12.96 13.33  9.72 12.14 15.13 11.52 12.94\n",
      " 10.89  9.36 11.78 10.05  6.44  8.86 11.85  8.24  9.66 12.85 11.32 13.74\n",
      " 12.01  8.4  10.82 12.85  9.24 10.66 13.74 12.21 14.63 15.   11.39 13.81\n",
      " 16.8  13.19 14.61 12.56 11.03 13.45 11.72  8.11 10.53 13.52  9.91 11.33\n",
      " 13.76 12.23 14.65 12.92  9.31 11.73 13.76 10.15 11.57  9.79  8.26 10.68\n",
      " 11.05  7.44  9.86 12.85  9.24 10.66 10.87  9.34 11.76 10.03  6.42  8.84\n",
      " 11.83  8.22  9.64 12.83 11.3  13.72 11.99  8.38 10.8  12.83  9.22 10.64\n",
      "  8.88  7.35  9.77 10.14  6.53  8.95 11.94  8.33  9.75  7.7   6.17  8.59\n",
      "  6.86  3.25  5.67  8.66  5.05  6.47  9.66  8.13 10.55  8.82  5.21  7.63\n",
      "  9.66  6.05  7.47 10.55  9.02 11.44 11.81  8.2  10.62 13.61 10.   11.42\n",
      "  9.37  7.84 10.26  8.53  4.92  7.34 10.33  6.72  8.14 10.57  9.04 11.46\n",
      "  9.73  6.12  8.54 10.57  6.96  8.38 11.44  9.91 12.33 12.7   9.09 11.51\n",
      " 14.5  10.89 12.31 12.52 10.99 13.41 11.68  8.07 10.49 13.48  9.87 11.29\n",
      " 14.48 12.95 15.37 13.64 10.03 12.45 14.48 10.87 12.29 10.53  9.   11.42\n",
      " 11.79  8.18 10.6  13.59  9.98 11.4   9.35  7.82 10.24  8.51  4.9   7.32\n",
      " 10.31  6.7   8.12 11.31  9.78 12.2  10.47  6.86  9.28 11.31  7.7   9.12\n",
      " 11.42  9.89 12.31 12.68  9.07 11.49 14.48 10.87 12.29 10.24  8.71 11.13\n",
      "  9.4   5.79  8.21 11.2   7.59  9.01 11.44  9.91 12.33 10.6   6.99  9.41\n",
      " 11.44  7.83  9.25]\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "tt = travel_time(np.zeros(nb_links))\n",
    "delta_csr = scipy.sparse.csr_matrix(delta)\n",
    "if debug:\n",
    "    print((delta_csr @ tt))\n",
    "    print(np.argmin(delta_csr @ tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We upload the flow allocation \n",
    "#### 3.1 We compute the travel time of each path. \n",
    "#### 3.2 We compute the all or nothing allocation by putting all the demand on shortest paths.\n",
    "#### 3.3 We update the flow allocation with a bisection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function potential is used to compute the line search between \n",
    "the all or nothing allocation and the current flow allocation\n",
    "The function potential returns the objective function corresponding to\n",
    "the flow allocation f.\n",
    "\"\"\"\n",
    "\n",
    "def potential(graph, f, c=-1):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    if c == -1:\n",
    "        c = [max_float for i in range(len(f))] # this might be to much, to do once we have everything done\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    pot_tmp = graph[:,3]*f + 1/2*graph[:,4]*(f**2) + 1/3*graph[:,5]*(f**3) + 1/4*graph[:,6]*(f**4) + 1/5*graph[:,7]*(f**5)\n",
    "    pot_tmp = [pot_tmp[i] if f[i]<c[i] else f[i]*max_float for i in range(len(f))]\n",
    "    return np.sum(pot_tmp)\n",
    "\n",
    "    # return np.sum(graph[:,3]*f + 1/2*graph[:,4]*(f**2) + 1/3*graph[:,5]*(f**3) + 1/4*graph[:,6]*(f**4) + 1/5*graph[:,7]*(f**5))\n",
    "    #links = int(np.max(graph[:, 0]) + 1)\n",
    "    #g = np.copy(\n",
    "    #    graph.dot(np.diag([1., 1., 1., 1., 1 / 2., 1 / 3., 1 / 4., 1 / 5.])))\n",
    "    #x = np.power(f.reshape((links, 1)), np.array([1, 2, 3, 4, 5]))\n",
    "    #return np.sum(np.einsum('ij,ij->i', x, g[:, 3:]))\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if debug:\n",
    "            print(potential(graph, (1. - a) * f_tmp.toarray()[0] + a * f_aon.toarray()[0], c))\n",
    "            print(l * d, end=\": \")\n",
    "            print(f(l * d))\n",
    "            print(r * d, end=\": \")\n",
    "            print(f(r * d))\n",
    "            print(str(m1 * d) + \" = \" + str(f(m1 * d)))\n",
    "            print(str(m2 * d) + \" = \" + str(f(m2 * d)))\n",
    "            print()\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t10.0\n"
     ]
    }
   ],
   "source": [
    "# check sparse vector\n",
    "h = scipy.sparse.lil_matrix(np.zeros(delta_csr.shape[0]))\n",
    "# the following is for one od\n",
    "demand[0][2] = 10\n",
    "# TO DO MODIFY TO TAKE INTO ACCOUNT SEVERALS OD\n",
    "h[:,0] = demand[0][2]\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_initial_flow(demand):\n",
    "    return h\n",
    "def solver(eps, nb_iter, demand, delta_csr, c=-1):\n",
    "    h = compute_initial_flow(demand)\n",
    "    for i in range(nb_iter):\n",
    "        f = h @ delta_csr\n",
    "        tt_flow = travel_time(f.toarray()[0], c)\n",
    "        tt_p = delta_csr @ tt_flow\n",
    "        # the following is for one od\n",
    "        p_aon = np.argmin(tt_p)\n",
    "        # the following is for one od\n",
    "        # TO MODIFY TO TAKE INTO ACCOUNT SEVERAL ODs\n",
    "        h_aon = scipy.sparse.lil_matrix(np.zeros(delta_csr.shape[0]))\n",
    "        h_aon[:, p_aon] = demand[0][2]\n",
    "        f_aon = h_aon @ delta_csr\n",
    "        t = potential(graph, f.toarray()[0])\n",
    "        s = line_search(lambda a: potential(graph, (1. - a) * f.toarray()[0] + a * f_aon.toarray()[0], c))\n",
    "        h = (1.-s)*h + s*h_aon\n",
    "        if s < eps:\n",
    "            break\n",
    "        if i % (nb_iter/20) == 0:\n",
    "            print(i)\n",
    "        if debug:\n",
    "            print(f.toarray()[0])\n",
    "            print(tt_flow)\n",
    "            print(tt_p)\n",
    "            print()\n",
    "            print(potential(graph,f.toarray()[0])-potential(graph, (1. - s) * f.toarray()[0] + s * f_aon.toarray()))\n",
    "            print(s)\n",
    "    if debug:\n",
    "        print(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-10\n",
    "nb_iter = 1000\n",
    "c = [100, 100, 2, 100, 100]\n",
    "\n",
    "h = solver(eps, nb_iter, demand, delta_csr, c)\n",
    "\n",
    "f = h @ delta_csr\n",
    "tt_flow = travel_time(f.toarray()[0], c)\n",
    "tt_p = delta_csr @ tt_flow\n",
    "\n",
    "if debug:\n",
    "    print(h)\n",
    "    print(tt_p[h.toarray()[0]!=0])\n",
    "    print(tt_flow)\n",
    "    print(delta_csr @ tt_flow)\n",
    "    print(np.argsort(delta_csr @ tt_flow))\n",
    "    print(h.toarray()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
