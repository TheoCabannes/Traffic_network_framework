{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code which solves the Static Traffic Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following problem (TAP-C):\n",
    "\\begin{align}\n",
    "\\min_{f, h} &\\sum_{a} \\int_{0}^{f_a} c_a(s)\\; \\text{d}s\n",
    "\\\\\n",
    "\\text{s.t.  } & \\;\\; f = \\Delta h\n",
    "\\\\\n",
    "& \\;\\; \n",
    "h \\geq 0\n",
    "\\\\\n",
    "& \\;\\; \n",
    "A h = d\n",
    "\\end{align}\n",
    "\n",
    "This problem is hard to compute, even if it is a convex problem. Computing all the path of a network is NP-hard (with respect to the number of edges and links).\n",
    "\n",
    "Nevertheless, the TAP can be solve using a Frank-Wolf algorithm:\n",
    "\\begin{align}\n",
    "&\\text{1. Write the pseudo code}\n",
    "\\\\\n",
    "&\\text{2. }\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "STA can be solve with link flows. But if you do that, you will not acces the path flows.\n",
    "\n",
    "It can also be solve using paths flow. \n",
    "This is hard, because finding every path in a network in a NP-complete problem.\n",
    "If you assume that you already know all the path in the network, you need a big memory.\n",
    "\n",
    "The tradeoff memory/running time has been, for years, done with low memory computers.\n",
    "Now, because we have HPC, we can use more memory. If we can now have more memory, we still can store all the possible path of a network. A idea would be to store only the path used in the network.\n",
    "\n",
    "To know the path used in the network, one can compute few steps of the Frank Wolfe algorithm.\n",
    "\n",
    "The running time bottle neck in the Frank Wolfe algorithm is computing the shortest path algorithm only with links flows.\n",
    "But if we have path flow, this could be way easier.\n",
    "This code is a trial to do such an algorithm. Test will be done once the proof of concept will be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We load the graph and the demand\n",
    "Both graph and demand are in csv file, we load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We need to demand to be an array like:\n",
    "[\n",
    "[o1, d1, demand from o1 to d1],\n",
    "...,\n",
    "[on, dn, demand from on to dn]\n",
    "]\n",
    "\n",
    "We need the graph to be an array like:\n",
    "[\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4],\n",
    "...,\n",
    "[id link n, node origin link n, node destination link n, a0, a1, a2, a3, a4]\n",
    "]\n",
    "where the node are indexed from 0 to nb_nodes-1,\n",
    "    the links are indexed from 0 to nb_links-1,\n",
    "    and a0, ..., a4 are the coeficient to calculate the travel time of one link as a function\n",
    "    of the flow on the link: t = a0 + a1 * f + a2 * f**2 + a3 * f**3 + a4 * f**4\n",
    "\n",
    "One can add some checks here to be sure that demand and graph respect this format!\n",
    "\n",
    "Some demand and graph data can be found on:\n",
    "    https://github.com/bstabler/TransportationNetworks\n",
    "    Here one need to perprocess the data before using this code\n",
    "\"\"\"\n",
    "\n",
    "def cleaning_input(graph, demand):\n",
    "    # in the case where there is only one o-d, then demand is interpret as a single row and not as a matrix (2d array)\n",
    "    try:\n",
    "        demand.shape[1]\n",
    "    except:\n",
    "        demand = np.array([demand])\n",
    "    nb_ods = int(demand.shape[0])\n",
    "\n",
    "    # in the case where the index of the od pairs does not begin by 0, we rename the od pairs\n",
    "    first_index_od = min(np.min(graph[:,1]), np.min(graph[:,2]))\n",
    "    graph[:,1] = graph[:,1]-first_index_od\n",
    "    graph[:,2] = graph[:,2]-first_index_od\n",
    "    demand[:,0] = demand[:,0] - first_index_od\n",
    "    demand[:,1] = demand[:,1] - first_index_od\n",
    "    # WE SHOULD ALSO CHECK THAT EVERY DEMAND IS WELL DEFINED: >0\n",
    "    return graph, demand\n",
    "\n",
    "def load_network(network):\n",
    "    graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "    demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)\n",
    "    graph, demand = cleaning_input(graph, demand)\n",
    "    if debug:\n",
    "        print(\"The network \" + network + \" has been charged. The network characteristics are:\")\n",
    "        nb_links = int(np.max(graph[:,0])+1)\n",
    "        nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "        nb_ods = int(demand.shape[0])\n",
    "        print(\"\\t nb nodes = \" + str(nb_nodes))\n",
    "        print(\"\\t nb links = \" + str(nb_links))\n",
    "        print(\"\\t nb ods = \" + str(nb_ods))\n",
    "    return graph, demand\n",
    "\n",
    "debug_local = True\n",
    "if debug_local:\n",
    "    network_name = 'data/SiouxFalls_bis'\n",
    "    graph, demand = load_network(network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link, a, b, B, power, c, fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the function which gives the travel time as a function of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "We define the travel time of each link as a function of the flow on each link.\n",
    "This function is given by the network topology (in the graph file) and by the capacity of each link.\n",
    "One row of the graph is:\n",
    "[id link 1, node origin link 1, node destination link 1, a0, a1, a2, a3, a4]\n",
    "Each row correspond to one link.\n",
    "The travel time of the link is t = fft * (1 + B * (f/c)^power)\n",
    "\"\"\"\n",
    "def travel_time(graph, f):\n",
    "    # here we need to have the same indexation for graph and f. That why we need to store graph in a dictionnary\n",
    "    # this could be changed\n",
    "    return graph[:,6] * (1 + graph[:,3]*(f/graph[:,5])**graph[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We compute the all or nothing flow allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Dijkstra's algorithm class of scipy we need to define the adjacent matrix of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We store the travel time of each link in a sparce adjacency matrix G.\n",
    "Given a flow allocation f and a capacities constraints c, we compute \n",
    "the travel time of each link and store it in G.\n",
    "\n",
    "This allow us after to us the Disjtra's algorithm of the class scipy.sparse.csgraph\n",
    "\"\"\"\n",
    "\n",
    "def update_travel_time_from_tt(graph, tt, nb_nodes):\n",
    "    G = np.zeros(shape=(nb_nodes,nb_nodes))\n",
    "    G = scipy.sparse.lil_matrix(G)\n",
    "    for i in range(graph.shape[0]):\n",
    "        G[int(graph[i][1]),int(graph[i][2])] = tt[i]\n",
    "    G = G.tocsr()\n",
    "    return G\n",
    "\n",
    "def update_travel_time_from_flow(graph, f, nb_nodes):\n",
    "    return update_travel_time_from_tt(graph,travel_time(graph, f), nb_nodes)\n",
    "\n",
    "debug_local = False\n",
    "if debug_local:\n",
    "    graph, _ = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes) # , [1,1,-1,1,1]))\n",
    "    print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because the classic Frank Wolf algorithm does not take into account the paths,\n",
    "we need to store the path in memory. We do it by using Object and a dictionnary \n",
    "called paths_used.\n",
    "\n",
    "This idea is that we do not want to compute all the possible paths of the network\n",
    "before the beginning of the algorithm. So we compute the paths used during the algorithm,\n",
    "and we store them in memory.\n",
    "\n",
    "We build at the same time the incidence matrix.\n",
    "\n",
    "CAREFUL. We use the number of links of the graph in the calcul of the hash of every path.\n",
    "This variable should be a parameter.\n",
    "\"\"\"\n",
    "\n",
    "# we need this class to know if we already know the path in the all or nothing part\n",
    "# the number of links of the network is needed to compute the hashcode of the path\n",
    "class path:\n",
    "    __nb_links = -1\n",
    "    def set_nb_links(nb_l):\n",
    "        path.__nb_links = nb_l\n",
    "    def __init__(self,links):\n",
    "        self.links = links\n",
    "        self.__flow = 0\n",
    "        if path.__nb_links == -1:\n",
    "            raise Exception('The number of links as not be defined inside the path class. We need it for defining the hash of a link. Please use the function path.set_nb_links(nb_links) to define it')\n",
    "    def set_flow(self, flow):\n",
    "        self.__flow = flow\n",
    "    def get_flow(self,):\n",
    "        return self.__flow\n",
    "    def __eq__(self, other):\n",
    "        return np.all(self.links == other.links)\n",
    "    # I am not sure about the hash table structure in Python. I am used to Java.\n",
    "    def __hash__(self):\n",
    "        return hash(np.sum([hash(self.links[i]*(path.__nb_links**i)) for i in range(len(self.links))]))\n",
    "    def __str__(self):\n",
    "        return str(self.__flow) + \" is on \" + str(self.links) \n",
    "\n",
    "debug_local = False\n",
    "if debug_local:\n",
    "    graph, _ = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    path.set_nb_links(nb_links)\n",
    "    paths_used = {}\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 1, 1, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)\n",
    "    p = path([0, 0, 2, 3])\n",
    "    paths_used[hash(p)] = (p, 0)\n",
    "    print(paths_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the all or nothing allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is the main point of the entire solver.\n",
    "It is the all or nothing allocation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "def build_graph_adjacency(graph):\n",
    "    graph_dict = {}\n",
    "    for i in range(graph.shape[0]):\n",
    "        try: \n",
    "            graph_dict[int(graph[i][1])]\n",
    "        except:\n",
    "            graph_dict[int(graph[i][1])] = {}\n",
    "        graph_dict[int(graph[i][1])][int(graph[i][2])] = int(graph[i][0])\n",
    "    return graph_dict\n",
    "\n",
    "# graph_dict gives the line of the graph matrix corresponding to the destination d and the origin o\n",
    "def build_demand_dict(demand):\n",
    "    demand_dict = {}\n",
    "    for i in range(demand.shape[0]):\n",
    "        try: \n",
    "            demand_dict[int(demand[i][0])]\n",
    "        except:\n",
    "            demand_dict[int(demand[i][0])] = {}\n",
    "        demand_dict[int(demand[i][0])][int(demand[i][1])] = i\n",
    "    return demand_dict\n",
    "\n",
    "def put_flow_on_short_path(faon, o_tmp, d_tmp, flow_tmp, return_predecessors, graph_dict, paths_used, paths_used_tmp, k, i):\n",
    "    node_tmp = d_tmp\n",
    "    links = []\n",
    "    # using the dijkstra, we build the fastest path and we put the flow on it.\n",
    "    while node_tmp != o_tmp:\n",
    "        if debug_local:\n",
    "            print(o_tmp)\n",
    "            print(node_tmp)\n",
    "        node_tmp_d = return_predecessors[o_tmp][node_tmp]\n",
    "        # Here we need the graph_dict to recover the link id from the nodes id.\n",
    "        link_tmp = graph_dict[node_tmp_d][node_tmp]\n",
    "        # we recover the path from the predecessor of the \n",
    "        links.insert(0, link_tmp)\n",
    "        faon[link_tmp] += flow_tmp\n",
    "        node_tmp = node_tmp_d\n",
    "\n",
    "    p = path(links)\n",
    "    p.set_flow(flow_tmp)\n",
    "\n",
    "\n",
    "    if debug_local:\n",
    "        print(p)\n",
    "    # If we do not already know p, we add it to the delta matrix (here a dict)\n",
    "    if not hash(p) in paths_used:\n",
    "        if debug_local:\n",
    "            print(k)\n",
    "        # we add p and his index\n",
    "        paths_used[hash(p)] = (p, k)\n",
    "        paths_used_tmp[hash(p)] = (p, k)\n",
    "        k = k+1\n",
    "    else:\n",
    "        # we recover the index of p using the paths_used dict\n",
    "        paths_used_tmp[hash(p)] = (p, paths_used[hash(p)][1])\n",
    "    return faon, paths_used, paths_used_tmp, k\n",
    "\n",
    "\n",
    "# computing the all or nothing flow\n",
    "def all_or_nothing_dikjstra(demand, G, graph_dict, paths_used, k):\n",
    "    # k is the next index to give to a new path.\n",
    "    debug_local = True\n",
    "    # paths_used_tmp is the set of the path in the all or nothing allocation of this step\n",
    "    paths_used_tmp = {}\n",
    "    # faon is the flow allocation of the all or nothing allocation\n",
    "    nb_links = G.nnz\n",
    "    faon = np.zeros(nb_links)\n",
    "    \n",
    "    # using scipy to compute dijkstra\"\n",
    "   \n",
    "    dist_matrix, return_predecessors = dijkstra(G, return_predecessors = True)\n",
    "    if debug_local:\n",
    "        print(return_predecessors)\n",
    "        \n",
    "    # for every origin destination pairs (i.e. one line of the demand file)\n",
    "    nb_ods = int(demand.shape[0])\n",
    "    for i in range(nb_ods):\n",
    "        # we compute the shortest path and add the demand on it.\n",
    "        o_tmp = int(demand[i][0])\n",
    "        d_tmp = int(demand[i][1])\n",
    "        flow_tmp = demand[i][2]\n",
    "        faon, paths_used, paths_used_tmp, k = put_flow_on_short_path(faon, o_tmp, d_tmp, flow_tmp, return_predecessors, graph_dict, paths_used, paths_used_tmp, k, i)\n",
    "\n",
    "    return faon, paths_used_tmp, paths_used, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_local = True\n",
    "if debug_local:\n",
    "    # we load the network\n",
    "    graph, demand = load_network(network_name)\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    print(nb_links)\n",
    "    path.set_nb_links(nb_links)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes)\n",
    "    graph_dict = build_graph_adjacency(graph)\n",
    "    paths_used = {}\n",
    "    k = 0 \n",
    "    _, _ , pp, k = all_or_nothing_dikjstra(demand, G, graph_dict, paths_used, k)\n",
    "    for p in pp.values():\n",
    "        print(p[0])\n",
    "    all_or_nothing_dikjstra(demand, G, graph_dict, paths_used, k)\n",
    "    for p in paths_used.values():\n",
    "        print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function potential is used to compute the line search between \n",
    "the all or nothing allocation and the current flow allocation\n",
    "The function potential returns the objective function corresponding to\n",
    "the flow allocation f.\n",
    "\n",
    "The function line search does a 1D line search.\n",
    "\"\"\"\n",
    "\n",
    "def potential(graph, f):\n",
    "    # this routine is useful for doing a line search\n",
    "    # computes the potential at flow assignment f\n",
    "    # here we need to have the same indexation for graph and f.\n",
    "    pot_tmp = graph[:,6] * (f + graph[:,3]*(f/(graph[:,4]+1))*(f/graph[:,5])**graph[:,4])\n",
    "    return np.sum(pot_tmp)\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    # on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    # of continuous convex function\n",
    "    # here we do a bisection\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let run the Frank-Wolf's algorithm with a line search to find alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(graph):\n",
    "    nb_links = int(np.max(graph[:,0])+1)\n",
    "    path.set_nb_links(nb_links)\n",
    "    nb_nodes = int(max(np.max(graph[:,1]), np.max(graph[:,2]))+1)\n",
    "    G = update_travel_time_from_flow(graph, np.zeros(nb_links), nb_nodes)\n",
    "    graph_dict = build_graph_adjacency(graph)\n",
    "    return nb_links, nb_nodes, G, graph_dict\n",
    "    \n",
    "def initialization_FW(demand, G, graph_dict, all_paths_used, k, graph, nb_nodes):\n",
    "    debug_local = False\n",
    "    \n",
    "    f, paths_used_for_this_iter, all_paths_used, k = all_or_nothing_dikjstra(demand, G, graph_dict, all_paths_used, k)\n",
    "    if debug_local:\n",
    "        print(G)\n",
    "        print(f)\n",
    "    G = update_travel_time_from_flow(graph, f, nb_nodes)\n",
    "    path_flow_matrix = np.zeros(k)\n",
    "    for val in paths_used_for_this_iter.values():\n",
    "        path_flow_matrix[val[1]] = val[0].get_flow()\n",
    "\n",
    "    if debug:\n",
    "        print(\"Test of initialization_FW\")\n",
    "        print(f)\n",
    "        for p in paths_used_for_this_iter.values():\n",
    "            print(p[0])\n",
    "        print(path_flow_matrix)\n",
    "    return f, paths_used_for_this_iter, all_paths_used, k, G, path_flow_matrix\n",
    "\n",
    "def iteration_FW(demand, G, graph_dict, all_paths_used, k, graph, f, nb_nodes, path_flow_matrix, i):\n",
    "    # WE COMPUTE THE ALL OR NOTHING ALGORITHM\n",
    "    faon, paths_used_for_this_iter, all_paths_used, k = all_or_nothing_dikjstra(demand, G, graph_dict, all_paths_used, k)\n",
    "    \n",
    "    # we find the better convex combinaison of f and faon\n",
    "    s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon))\n",
    "    # HERE WE SHOULD BE CAREFUL IN THE CASE WHERE WE HAVE THE CAPACITY CONSTRAINTS\n",
    "    # THE GRADIENT OF THE FUNCTION IS NOT THE SHORTEST PATH\n",
    "    # WE SHOULD REMOVE THE PATH THAT SATURATED THE LINKS\n",
    "    # AND THEN COMPUTE THE SOLUTION WITHOUT THE SATURATION, AND WITHOUT THE \n",
    "    # CORRESPONDING DEMAND\n",
    "    if s==0:\n",
    "        update_flow = True\n",
    "        \n",
    "        demand_tmp = demand.copy()\n",
    "        nb_links = int(np.max(graph[:,0])+1)\n",
    "        _, delta, route2od = output_FW(all_paths_used, nb_links, graph, f, demand)\n",
    "        # WE COMPUTE THE ALL OR NOTHING ALGORITHM\n",
    "        faon, paths_used_for_this_iter, all_paths_used, k = all_or_nothing_dikjstra(demand_tmp, G, graph_dict, all_paths_used, k)\n",
    "\n",
    "        # I add the flow of the saturated path to faon \n",
    "        for path_c in path_at_capacity:\n",
    "            for j in np.where(delta[path_c].toarray()[0]==1):\n",
    "                for jj in j:\n",
    "                    faon[jj] += path_flow_matrix[path_c]\n",
    "\n",
    "        # we find the better convex combinaison of f and faon\n",
    "        s = line_search(lambda a: potential(graph, (1. - a) * f + a * faon))\n",
    "        if debug:\n",
    "            print(s)\n",
    "            print(potential(graph, (1. - s) * f + s * faon))\n",
    "        for path_c in path_at_capacity:\n",
    "            path_flow_matrix[path_c] = path_flow_matrix[path_c] /(1-s) \n",
    "    else:\n",
    "        update_flow = False\n",
    "    f = (1. - s) * f + s * faon\n",
    "    G = update_travel_time_from_flow(graph, f, nb_nodes)\n",
    "\n",
    "    # we multiply the previous path flow matrix by the coeficient of the line search\n",
    "    path_flow_matrix = (1-s) * path_flow_matrix\n",
    "    # we add the new path at the end of the path flow matrix.\n",
    "    path_flow_matrix = np.append(path_flow_matrix, np.zeros(len(all_paths_used)-path_flow_matrix.shape[0]))\n",
    "    # we add the all or nothing path flow (mulitply by the coeficient of the line search) to the path flow matrix.\n",
    "    for val in paths_used_for_this_iter.values():\n",
    "        # val[1] is the index of the path, val[0] is the path object\n",
    "        path_flow_matrix[val[1]] += s * val[0].get_flow()\n",
    "\n",
    "    if debug and i % (nb_iter / 10) == 0:\n",
    "        print(\"Iteration: \" + str(i))\n",
    "        print(\"demand = \" + str(demand))\n",
    "        print(\"s: \" + str(s))\n",
    "        print(\"h: \" +str(path_flow_matrix))\n",
    "        print(\"f: \" + str(f))\n",
    "        print(\"The paths used at this iteration are:\")\n",
    "        for p in paths_used_for_this_iter.values():\n",
    "            print(p[0])\n",
    "    return path_flow_matrix, f, G, all_paths_used, k, s\n",
    "\n",
    "def output_FW(all_paths_used, nb_links, graph, f, demand):\n",
    "    # MAYBE I SHOULD SPLIT THE CODE HERE TO MAKE EASIER TEST\n",
    "    # At the end we do some work to return a proper output\n",
    "    nb_paths = len(all_paths_used.keys())\n",
    "    delta = np.zeros(shape=(nb_paths, nb_links)) # nb_links should be a parameter\n",
    "    route2od = [0 for _ in range(nb_paths)]# np.zeros(shape=nb_paths)\n",
    "    delta = scipy.sparse.lil_matrix(delta)\n",
    "    tt_f = np.array(travel_time(graph, f))\n",
    "    \n",
    "    demand_dict = build_demand_dict(demand)\n",
    "\n",
    "    for p in all_paths_used.values():\n",
    "        # here I can built route2od matrix at the same time\n",
    "        try:\n",
    "            links_tmp = p[0].links\n",
    "            for l in links_tmp:\n",
    "                delta[p[1],l] = 1\n",
    "            route2od[p[1]] = demand_dict[int(graph[int(links_tmp[0])][1])][int(graph[int(links_tmp[-1])][2])]\n",
    "        except:\n",
    "            ;\n",
    "    delta = delta.tocsr()\n",
    "    # I should built the route2od matrix here,\n",
    "    # route2od should be build from the all_paths_used_dict\n",
    "    return tt_f, delta, route2od\n",
    "\n",
    "see_results = False\n",
    "def Frank_Wolf_solver(graph, demand_bis, eps, nb_iter):\n",
    "    ######### FIRST, WE INITIALIZE THE ALGORITHM #########\n",
    "    # We initialize the number of paths_used to 0, \n",
    "    k = 0\n",
    "    all_paths_used = {}\n",
    "    \n",
    "    # we built the network as a matrix from the graph file\n",
    "    nb_links, nb_nodes, G, graph_dict = build_network(graph)\n",
    "    \n",
    "    # The initialization step: we put all the demand on the fastest free flow travel time paths.\n",
    "    f, paths_used_for_this_iter, all_paths_used, k, G, path_flow_matrix = initialization_FW(demand_bis, G, graph_dict, all_paths_used, k, graph, nb_nodes)\n",
    "\n",
    "    ######### THEN, I RUN THE ITERATION OF THE FRANK-WOLF ALGORITHM #########\n",
    "    for i in range(nb_iter):\n",
    "        path_flow_matrix, f, G, all_paths_used, k, s = iteration_FW(demand_bis, G, graph_dict, all_paths_used, k, graph, f, nb_nodes, path_flow_matrix, i)\n",
    "        if s < eps:\n",
    "            if see_results:\n",
    "                print(i, s)\n",
    "            break\n",
    "        if see_results and (i % (nb_iter/20)==0):\n",
    "            print(\"Iteration \" + str(i) + \", error = \" + str(s))\n",
    "    if debug:\n",
    "        print(path_flow_matrix)\n",
    "       \n",
    "    ######### FINALLY, I WORK ON THE OUTPUT TO RETURN #########\n",
    "    tt_f, delta, route2od = output_FW(all_paths_used, nb_links, graph, f, demand_bis)\n",
    "    return path_flow_matrix, tt_f, delta.toarray(), route2od\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wardrop(j, demand, route2od, delta, path_flow_matrix, tt_f):\n",
    "    f = delta.T @ path_flow_matrix\n",
    "    tt_p = delta @ tt_f\n",
    "    od = j\n",
    "    tab = []\n",
    "    for i in range(len(route2od)):\n",
    "        if route2od[i] == od:\n",
    "            tab.append(i)\n",
    "    print(od)\n",
    "    print(tab)\n",
    "    print(tt_p[tab])\n",
    "\n",
    "def od2route(route2od):\n",
    "    od2route = {}\n",
    "    for i in range(len(route2od)):\n",
    "        if route2od[i] not in od2route.keys():\n",
    "            od2route[route2od[i]] = set()\n",
    "        od2route[route2od[i]].add(i)\n",
    "    print(route2od)\n",
    "    return od2route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Siou2 = 'data/SiouxFalls_bis'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "debug=True\n",
    "\n",
    "network_name = Siou2\n",
    "eps=1e-8\n",
    "nb_iter = 1000\n",
    "graph, demand = load_network(network_name)\n",
    "if network_name == Brae:\n",
    "    demand[0][2] = 10\n",
    "\n",
    "debug = False\n",
    "see_results = True\n",
    "\n",
    "path_flow_matrix, tt_f, delta, route2od = Frank_Wolf_solver(graph, demand, eps, nb_iter) #, [11,11,2,11,11])\n",
    "\n",
    "if debug:\n",
    "    nb_paths = len(path_flow_matrix)\n",
    "    print(path_flow_matrix)\n",
    "    print(nb_paths)\n",
    "    print(tt_f)\n",
    "    print(delta)\n",
    "    print(delta @ tt_f)\n",
    "    print(route2od)\n",
    "    print(delta.shape)\n",
    "    print(od2route(route2od))\n",
    "    for od in od2route(route2od).keys():\n",
    "        print(\"check wardrop for the od: \" + str(od))\n",
    "        check_wardrop(od, demand, route2od, delta, path_flow_matrix, tt_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_f)\n",
    "f = delta.T @ path_flow_matrix\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = np.loadtxt(network_name + '_result.csv', delimiter=',', skiprows=1)\n",
    "# print(solution[:,1] - f)\n",
    "print(f[27])\n",
    "print(f[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution[:,2] - tt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Siou2 = 'data/SiouxFalls_bis'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "debug=True\n",
    "\n",
    "network_name = Siou2\n",
    "eps=1e-8\n",
    "nb_iter = 1000\n",
    "graph, demand = load_network(network_name)\n",
    "\n",
    "u = np.ones(int(np.max(graph[:,0])+1))\n",
    "u = u * 50000\n",
    "u[27] = 20000\n",
    "u[42] = 20000\n",
    "debug = False\n",
    "see_results = True\n",
    "float_appro = 1e-3\n",
    "\n",
    "path_flow_matrix, tt_f, delta, route2od = Frank_Wolf_solver(graph, demand, eps, nb_iter, u) #, [11,11,2,11,11])\n",
    "\n",
    "if debug:\n",
    "    nb_paths = len(path_flow_matrix)\n",
    "    print(path_flow_matrix)\n",
    "    print(nb_paths)\n",
    "    print(tt_f)\n",
    "    print(delta)\n",
    "    print(delta @ tt_f)\n",
    "    print(route2od)\n",
    "    print(delta.shape)\n",
    "    print(od2route(route2od))\n",
    "    for od in od2route(route2od).keys():\n",
    "        print(\"check wardrop for the od: \" + str(od))\n",
    "        check_wardrop(od, demand, route2od, delta, path_flow_matrix, tt_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((delta.T @ path_flow_matrix)[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# New try\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "network = 'data/SiouxFalls_bis'\n",
    "# network = 'data/Braess_bis'\n",
    "graph = np.loadtxt(network + '_net.csv', delimiter=',', skiprows=1)\n",
    "demand = np.loadtxt(network + '_od.csv', delimiter=',', skiprows=1)\n",
    "t0 = graph[:,6]\n",
    "B = graph[:,3]\n",
    "c = graph[:,5]\n",
    "power = graph[:,4]\n",
    "nb_links = graph.shape[0]\n",
    "del graph\n",
    "\n",
    "# here we shoud read delta and route2od."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  4.  6.  5.  4.  4.  4.  4.  2.  6.  2.  4.  5.  5.  4.  2.  3.  2.\n",
      "  2.  3. 10.  5.  5. 10.  3.  3.  5.  6.  4.  8.  6.  5.  6.  4.  4.  6.\n",
      "  3.  3.  4.  4.  5.  4.  6.  5.  3.  3.  5.  4.  2.  3.  8.  2.  2.  2.\n",
      "  3.  4.  3.  2.  4.  4.  4.  6.  5.  6.  2.  3.  3.  5.  2.  4.  4.  4.\n",
      "  2.  4.  3.  2.]\n"
     ]
    }
   ],
   "source": [
    "f = np.zeros(nb_links)\n",
    "tt = t0 * (1 + B*(f/c)**power)\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.9   4.6   6.9   5.75  4.6   4.6   4.6   4.6   2.3   6.9   2.3   4.6\n",
      "  5.75  5.75  4.6   2.3   3.45  2.3   2.3   3.45 11.5   5.75  5.75 11.5\n",
      "  3.45  3.45  5.75  6.9   4.6   9.2   6.9   5.75  6.9   4.6   4.6   6.9\n",
      "  3.45  3.45  4.6   4.6   5.75  4.6   6.9   5.75  3.45  3.45  5.75  4.6\n",
      "  2.3   3.45  9.2   2.3   2.3   2.3   3.45  4.6   3.45  2.3   4.6   4.6\n",
      "  4.6   6.9   5.75  6.9   2.3   3.45  3.45  5.75  2.3   4.6   4.6   4.6\n",
      "  2.3   4.6   3.45  2.3 ]\n",
      "[ 6.00081624  4.00869075  6.00083412  6.57359826  4.00858665  4.26940183\n",
      "  4.02017916  4.27126776  2.31537411  7.13330048  2.31707223  9.99822521\n",
      "  9.65131071  6.59951767 10.02070256 14.690955    5.55216038  2.06222569\n",
      " 14.82415952  5.50141296 15.17470751 10.72947353  9.67015456 15.0378695\n",
      "  5.68253305  5.71724339 12.40568945 13.72237028 20.08480998 16.30801715\n",
      "  7.22302456 12.20325453 13.59022763 13.69128569  4.01979049 13.73515565\n",
      "  3.02279654  3.02347967 17.66100772 13.84264505 12.23433913  9.07934431\n",
      " 13.81156045 12.37460486  4.32621208  9.08814367 10.77881157 20.2362757\n",
      "  9.50145849  3.1634648  16.30801715  9.47285442  7.4366268   2.06318639\n",
      "  3.16583488  4.25937109  4.33553079  7.41227404  9.45906351  4.26023007\n",
      "  9.5152494   8.16566081  7.71313     8.08163569  4.21350583 11.92405983\n",
      "  9.05716718  7.71313     4.20104986 12.3658055   9.06596654 12.24313849\n",
      "  3.75930419 17.61702072 11.75257941  3.72294674]\n"
     ]
    }
   ],
   "source": [
    "solution = np.loadtxt(network + '_result.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "tt = t0 * (1 + B*(solution[:,1]/c)**power)\n",
    "\n",
    "print(tt)\n",
    "print(solution[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_all_or_nothing(demand, tt, delta, od2route):\n",
    "    \"\"\"\n",
    "    All or nothing allocation using the incidence matrix.\n",
    "    \"\"\"\n",
    "    np_paths = delta.shape[1]\n",
    "    hp = np.zeros(np_paths)\n",
    "    tp = delta.T @ tt\n",
    "    for od in range(demand.shape[0]):\n",
    "        # pour l'instant que une od\n",
    "        tp_tmp = tp[np.nonzero(np.array(od2route) == od)]\n",
    "        shortest_path = np.argmin(tp_tmp)\n",
    "        hp[shortest_path] = demand[od][2]\n",
    "    return hp\n",
    "\n",
    "def potential(f, t0, B, c, power):\n",
    "    \"\"\"\n",
    "    This routing is useful for doing a line search.\n",
    "    It computes the potential at flow assignment f.\n",
    "    \"\"\"\n",
    "    return np.sum(t0*(f + B * (f/(power+1))*((f/c)**power)))\n",
    "\n",
    "\n",
    "def line_search(f, res=20):\n",
    "    \"\"\"\n",
    "    on a grid of 2^res points bw 0 and 1, find global minimum\n",
    "    of continuous convex function\n",
    "    here we do a bisection\n",
    "    \"\"\"\n",
    "    d = 1. / (2**res - 1)\n",
    "    l, r = 0, 2**res - 1\n",
    "    while r - l > 1:\n",
    "        if f(l * d) <= f(l * d + d):\n",
    "            return l * d\n",
    "        if f(r * d - d) >= f(r * d):\n",
    "            return r * d\n",
    "        # otherwise f(l) > f(l+d) and f(r-d) < f(r)\n",
    "        m1, m2 = (l + r) / 2, 1 + (l + r) / 2\n",
    "        if f(m1 * d) < f(m2 * d):\n",
    "            r = m1\n",
    "        if f(m1 * d) > f(m2 * d):\n",
    "            l = m2\n",
    "        if f(m1 * d) == f(m2 * d):\n",
    "            return m1 * d\n",
    "    return l * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Frank_Wolf_solver\n",
    "I210 = 'data/I210'\n",
    "Chic = 'data/Chicago'\n",
    "Anah = 'data/Anaheim'\n",
    "Siou = 'data/SiouxFalls'\n",
    "Brae = 'data/braess'\n",
    "\n",
    "network_name = Brae\n",
    "\n",
    "eps=1e-8\n",
    "nb_iter = 1000\n",
    "graph, demand = Frank_Wolf_solver.load_network(network_name)\n",
    "if network_name == Brae:\n",
    "    demand[0][2] = 10\n",
    "path_flow_matrix, tt_f, delta, route2od = Frank_Wolf_solver.Frank_Wolf_solver(graph, demand, eps, nb_iter)\n",
    "delta = delta.T\n",
    "print(path_flow_matrix)\n",
    "print(tt_f)\n",
    "print(delta)\n",
    "print(delta.T @ tt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = np.array([3.5, 5.6, 3.2, 3.7, 5.8])\n",
    "test_route = np.array([0, 1, 0, 0, 1])\n",
    "print(test_route)\n",
    "print(test_path)\n",
    "indices = np.nonzero(test_route == 0)\n",
    "print(indices)\n",
    "print(test_path[indices])\n",
    "print(np.argmin(test_path[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an first test\n",
    "hp = path_all_or_nothing(demand, tt, delta, route2od)\n",
    "f = delta @ hp\n",
    "\n",
    "i = 0\n",
    "nb_iters = 100\n",
    "while i < nb_iters:\n",
    "    tt = t0 * (1 + B*(f/c)**power)\n",
    "    hpaon = path_all_or_nothing(demand, tt, delta, route2od)\n",
    "    faon = delta @ hpaon\n",
    "    s = line_search(lambda a: potential((1. - a) * f + a * faon, t0, B, c, power))\n",
    "    hp = s*hpaon + (1-s)*hp\n",
    "    f = delta @ hp\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.zeros(nb_links)\n",
    "tt = t0 * (1 + B*(f/c)**power)\n",
    "f = all_or_nothing(demand, tt, delta, od2route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One possibility\n",
    "# TO DO: WRITE all_or_nothing and line_search\n",
    "i = 0\n",
    "while i<10:\n",
    "    faon = all_or_nothing(g, tt, demand)\n",
    "    f = line_search(f, faon, lambda a: np.sum(t0*(a + B * (a/(power+1))*((a/c)**power))))\n",
    "    tt = t0 * (1 + B*(f/c)**power)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a last one\n",
    "all_or_nothing(g, tt)\n",
    "    tp = delta.T @ tt\n",
    "    p = np.argmin(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_or_nothing(g, tt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
